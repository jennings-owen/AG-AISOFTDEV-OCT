{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Lab 2: Refactoring & Documentation\n",
    "\n",
    "**Objective:** Use an LLM to refactor a complex Python function to improve its readability and maintainability, and then generate comprehensive, high-quality documentation for the project.\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Writing code is only the first step; writing *good* code is what makes a project successful in the long run. In this lab, you will use an LLM as a code quality expert. You will refactor a poorly written function to make it cleaner and then generate professional-grade documentation, including docstrings and a README file. These are high-value tasks that AI can significantly accelerate.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will set up our environment and define a sample of poorly written code that we will use as the target for our refactoring and documentation efforts.\n",
    "\n",
    "**Model Selection:**\n",
    "Models with strong coding and reasoning abilities are best for this task. `gpt-4.1`, `o3`, or `codex-mini` are great choices. You can also try more general models like `gemini-2.5-pro`.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `save_artifact()`: To save the generated README file.\n",
    "- `clean_llm_output()`: To clean up the generated code and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 17:39:42,982 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Code to Improve\n",
    "\n",
    "Here is a sample Python function that is functional but poorly written. It's hard to read, has no comments or type hints, and mixes multiple responsibilities. This is the code we will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_code = \"\"\"\n",
    "def process_data(data, operation):\n",
    "    if operation == 'sum':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total\n",
    "    elif operation == 'average':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total / len(data)\n",
    "    elif operation == 'max':\n",
    "        max_val = data[0]\n",
    "        for i in data:\n",
    "            if i > max_val:\n",
    "                max_val = i\n",
    "        return max_val\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Refactoring the Code\n",
    "\n",
    "**Task:** Use the LLM to refactor the `bad_code` to be more readable, efficient, and maintainable.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a senior Python developer.\n",
    "2.  Provide the `bad_code` as context.\n",
    "3.  Ask the LLM to refactor the code. Be specific about the improvements you want, such as:\n",
    "    * Breaking the single function into multiple, smaller functions.\n",
    "    * Using built-in Python functions where appropriate (e.g., `sum()`, `max()`).\n",
    "    * Adding clear type hints and return types.\n",
    "\n",
    "> **Tip:** When you ask the AI to refactor, give it a principle to follow. For example, ask it to apply the 'Single Responsibility Principle,' which means each function should do only one thing. This guides the AI to create cleaner, more modular code.\n",
    "\n",
    "**Expected Quality:** A block of Python code that is functionally identical to the original but is significantly cleaner, more modular, and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refactoring Code ---\n",
      "import collections.abc\n",
      "from enum import Enum, auto\n",
      "from typing import Callable, Dict, List, Union\n",
      "\n",
      "# Use a type alias for clarity and reusability.\n",
      "Numeric = Union[int, float]\n",
      "DataList = List[Numeric]\n",
      "\n",
      "\n",
      "class Operation(Enum):\n",
      "    \"\"\"Defines the supported data processing operations in a type-safe way.\"\"\"\n",
      "    SUM = auto()\n",
      "    AVERAGE = auto()\n",
      "    MAX = auto()\n",
      "\n",
      "\n",
      "def calculate_sum(data: DataList) -> Numeric:\n",
      "    \"\"\"\n",
      "    Calculates the sum of a list of numbers using the built-in sum() function.\n",
      "\n",
      "    Args:\n",
      "        data: A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        The sum of the numbers in the list.\n",
      "    \"\"\"\n",
      "    return sum(data)\n",
      "\n",
      "\n",
      "def calculate_average(data: DataList) -> float:\n",
      "    \"\"\"\n",
      "    Calculates the average of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        data: A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        The average of the numbers.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the input list is empty.\n",
      "    \"\"\"\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "\n",
      "def find_max(data: DataList) -> Numeric:\n",
      "    \"\"\"\n",
      "    Finds the maximum value in a list of numbers using the built-in max() function.\n",
      "\n",
      "    Args:\n",
      "        data: A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        The maximum number in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the input list is empty.\n",
      "    \"\"\"\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum value of an empty list.\")\n",
      "    return max(data)\n",
      "\n",
      "\n",
      "# This dictionary maps each operation to its corresponding function.\n",
      "# This approach follows the Open/Closed Principle: to add a new operation,\n",
      "# you can add a new function and a new entry to this dictionary without\n",
      "# modifying the existing `process_data` function.\n",
      "_OPERATION_HANDLERS: Dict[Operation, Callable[[DataList], Numeric]] = {\n",
      "    Operation.SUM: calculate_sum,\n",
      "    Operation.AVERAGE: calculate_average,\n",
      "    Operation.MAX: find_max,\n",
      "}\n",
      "\n",
      "\n",
      "def process_data(data: DataList, operation: Operation) -> Numeric:\n",
      "    \"\"\"\n",
      "    Processes a list of numbers based on a specified operation.\n",
      "\n",
      "    This function acts as a dispatcher, delegating the actual computation\n",
      "    to a specialized handler function based on the 'operation' parameter.\n",
      "    This design avoids complex conditional logic and adheres to the Single\n",
      "    Responsibility and Open/Closed principles.\n",
      "\n",
      "    Args:\n",
      "        data: A list of numbers (integers or floats) to process.\n",
      "        operation: An 'Operation' enum member specifying the action to perform.\n",
      "\n",
      "    Returns:\n",
      "        The result of the operation as an integer or float.\n",
      "\n",
      "    Raises:\n",
      "        NotImplementedError: If the provided operation is not supported.\n",
      "    \"\"\"\n",
      "    if not isinstance(data, collections.abc.Sequence):\n",
      "        raise TypeError(\"Input 'data' must be a sequence (e.g., a list).\")\n",
      "\n",
      "    handler = _OPERATION_HANDLERS.get(operation)\n",
      "    if handler:\n",
      "        return handler(data)\n",
      "    else:\n",
      "        raise NotImplementedError(f\"Operation '{operation.name}' is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "refactor_prompt = f\"\"\"\n",
    "You are a senior Python developer and clean code expert. Refactor any python code provided to improve its structure, readability, and efficiency without changing its functionality. Apply best practices such as removing redundancy, improving variable names, and simplifying logic.\n",
    "\n",
    "# INPUT CODE:\n",
    "{bad_code}\n",
    "\n",
    "Follow these guidelines:\n",
    " 1. Always use SOLID principles.\n",
    " 2. Write additional helper methods if necessary to ensure Single Responsibility Principle.\n",
    " 3. Include comments and docstrings for function and class declarations.\n",
    " 4. Use built-in functions and libraries where applicable.\n",
    " 5. Add clear type hints and return types.\n",
    " 7. Do not include starting or ending markdown syntax.\n",
    " 8. Avoid nesting code too deeply to improve readability.\n",
    " 9. Avoid String literals for operations, use Enums where applicable.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring Code ---\")\n",
    "refactored_code = get_completion(refactor_prompt, client, model_name, api_provider)\n",
    "cleaned_code = clean_llm_output(refactored_code, language='python')\n",
    "print(cleaned_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Docstrings\n",
    "\n",
    "**Task:** Prompt the LLM to generate high-quality docstrings for the newly refactored code.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide the `refactored_code` from the previous step as context.\n",
    "3.  Instruct the LLM to generate Google-style Python docstrings for each function.\n",
    "4.  The docstrings should include a description of the function, its arguments (`Args:`), and what it returns (`Returns:`).\n",
    "\n",
    "**Expected Quality:** The refactored Python code, now with complete and professional-looking docstrings for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Docstrings ---\n",
      "import collections.abc\n",
      "from enum import Enum, auto\n",
      "from typing import Callable, Dict, List, Union\n",
      "\n",
      "# Use a type alias for clarity and reusability.\n",
      "Numeric = Union[int, float]\n",
      "DataList = List[Numeric]\n",
      "\n",
      "\n",
      "class Operation(Enum):\n",
      "    \"\"\"Defines the supported data processing operations.\n",
      "\n",
      "    This enumeration provides a type-safe way to specify which data processing\n",
      "    operation should be performed.\n",
      "\n",
      "    Attributes:\n",
      "        SUM: Represents the summation of all numbers in a list.\n",
      "        AVERAGE: Represents the calculation of the average of numbers in a list.\n",
      "        MAX: Represents finding the maximum number in a list.\n",
      "    \"\"\"\n",
      "    SUM = auto()\n",
      "    AVERAGE = auto()\n",
      "    MAX = auto()\n",
      "\n",
      "\n",
      "def calculate_sum(data: DataList) -> Numeric:\n",
      "    \"\"\"Calculates the sum of a list of numbers using the built-in sum() function.\n",
      "\n",
      "    Args:\n",
      "        data (DataList): A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The sum of the numbers in the list.\n",
      "    \"\"\"\n",
      "    return sum(data)\n",
      "\n",
      "\n",
      "def calculate_average(data: DataList) -> float:\n",
      "    \"\"\"Calculates the average of a list of numbers.\n",
      "\n",
      "    Args:\n",
      "        data (DataList): A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the numbers.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the input list is empty.\n",
      "    \"\"\"\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "\n",
      "def find_max(data: DataList) -> Numeric:\n",
      "    \"\"\"Finds the maximum value in a list of numbers using the built-in max() function.\n",
      "\n",
      "    Args:\n",
      "        data (DataList): A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The maximum number in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the input list is empty.\n",
      "    \"\"\"\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum value of an empty list.\")\n",
      "    return max(data)\n",
      "\n",
      "\n",
      "# This dictionary maps each operation to its corresponding function.\n",
      "# This approach follows the Open/Closed Principle: to add a new operation,\n",
      "# you can add a new function and a new entry to this dictionary without\n",
      "# modifying the existing `process_data` function.\n",
      "_OPERATION_HANDLERS: Dict[Operation, Callable[[DataList], Numeric]] = {\n",
      "    Operation.SUM: calculate_sum,\n",
      "    Operation.AVERAGE: calculate_average,\n",
      "    Operation.MAX: find_max,\n",
      "}\n",
      "\n",
      "\n",
      "def process_data(data: DataList, operation: Operation) -> Numeric:\n",
      "    \"\"\"Processes a list of numbers based on a specified operation.\n",
      "\n",
      "    This function acts as a dispatcher, delegating the actual computation\n",
      "    to a specialized handler function based on the 'operation' parameter.\n",
      "    This design avoids complex conditional logic and adheres to the Single\n",
      "    Responsibility and Open/Closed principles.\n",
      "\n",
      "    Args:\n",
      "        data (DataList): A list of numbers (integers or floats) to process.\n",
      "        operation (Operation): An 'Operation' enum member specifying the action\n",
      "            to perform.\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The result of the operation as an integer or float.\n",
      "\n",
      "    Raises:\n",
      "        TypeError: If the input 'data' is not a sequence.\n",
      "        NotImplementedError: If the provided operation is not supported.\n",
      "    \"\"\"\n",
      "    if not isinstance(data, collections.abc.Sequence):\n",
      "        raise TypeError(\"Input 'data' must be a sequence (e.g., a list).\")\n",
      "\n",
      "    handler = _OPERATION_HANDLERS.get(operation)\n",
      "    if handler:\n",
      "        return handler(data)\n",
      "    else:\n",
      "        raise NotImplementedError(f\"Operation '{operation.name}' is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "docstring_prompt = f\"\"\"\n",
    "You are a senior Python developer and documentation expert. Add Google-style docstrings to all functions and classes in the provided Python code. Ensure that each docstring includes a brief description of the function/class, its parameters with types, and the return type.\n",
    "The docstrings should include a description of the function, its arguments (`Args:`), and what it returns (`Returns:`).\n",
    "\n",
    "\n",
    "# INPUT CODE:\n",
    "{cleaned_code}\n",
    "\n",
    "# IMPORTANT: \n",
    "1. Do not change any code, only add docstrings.\n",
    "2. The code might already have docstrings. Only add docstrings where they are missing. \n",
    "3. Modify existing docstrings to ensure they follow the format specified above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Docstrings ---\")\n",
    "code_with_docstrings = get_completion(docstring_prompt, client, model_name, api_provider)\n",
    "cleaned_code_with_docstrings = clean_llm_output(code_with_docstrings, language='python')\n",
    "print(cleaned_code_with_docstrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Generating a Project README\n",
    "\n",
    "**Task:** Generate a comprehensive `README.md` file for the entire Onboarding Tool project.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a final prompt that instructs the LLM to act as a technical writer.\n",
    "2.  This time, you will provide multiple pieces of context: the `day1_prd.md` and the `app/main.py` source code. (You will need to load these files).\n",
    "3.  Ask the LLM to generate a `README.md` file with the following sections:\n",
    "    * Project Title\n",
    "    * Overview (based on the PRD)\n",
    "    * Features\n",
    "    * API Endpoints (with `curl` examples)\n",
    "    * Setup and Installation instructions.\n",
    "4.  Save the final output to `README.md` in the project's root directory.\n",
    "\n",
    "**Expected Quality:** A complete, professional `README.md` file that provides a comprehensive overview of the project for other developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Project README ---\n",
      "# Ascend Onboarding Platform API\n",
      "\n",
      "Welcome to the Ascend Onboarding Platform API, the backend service powering a revolutionary new hire experience. This project aims to transform a typically fragmented process into a structured, engaging, and efficient journey.\n",
      "\n",
      "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
      "[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n",
      "[![Framework](https://img.shields.io/badge/Framework-FastAPI-green)](https://fastapi.tiangolo.com/)\n",
      "\n",
      "---\n",
      "\n",
      "## Overview\n",
      "\n",
      "The Ascend Onboarding Platform is designed to solve the common challenges of new hire onboarding. New employees often face an overwhelming amount of information, while HR and managers lack centralized tools to track progress and provide support.\n",
      "\n",
      "This API provides the core infrastructure to:\n",
      "-   **For New Hires (`Eager Contributors`):** Create personalized learning paths and provide a central hub for resources.\n",
      "-   **For HR Specialists (`Onboarding Orchestrators`):** Streamline administrative tasks and monitor the progress of all new hires from a single dashboard.\n",
      "-   **For Managers (`Team Integrators`):** Easily assign mentors, track skill development, and accelerate a new member's integration into the team.\n",
      "\n",
      "This repository contains the foundational User Management service, built with FastAPI and SQLAlchemy, which serves as the backbone for the entire platform.\n",
      "\n",
      "## Features\n",
      "\n",
      "This API provides the core functionality for managing users within the Ascend platform.\n",
      "\n",
      "-   **Comprehensive User Model:** The database schema includes detailed user attributes such as role, department, manager, mentor, start date, and experience level.\n",
      "-   **CRUD Operations for Users:** Full Create, Read, Update, and Delete functionality for all user profiles.\n",
      "-   **Role-Based User Types:** Differentiates between user types (`new_hire`, `manager`, `hr_specialist`, `employee`) to enable tailored experiences.\n",
      "-   **Relational Mapping:** Establishes clear relationships between users, including manager-to-direct-report and mentor-to-mentee pairings.\n",
      "-   **Scalable Architecture:** Built on FastAPI for high performance and automatic interactive API documentation.\n",
      "-   **SQLite Database:** Uses a simple, file-based SQLite database for easy setup and local development.\n",
      "\n",
      "## API Endpoints\n",
      "\n",
      "All endpoints are available under the base URL: `http://127.0.0.1:8000`\n",
      "\n",
      "### Users\n",
      "\n",
      "#### 1. Create a New User\n",
      "\n",
      "Creates a new user in the system. The email address must be unique.\n",
      "\n",
      "-   **Method:** `POST`\n",
      "-   **Path:** `/users/`\n",
      "-   **Request Body:** A JSON object matching the `UserCreate` schema.\n",
      "\n",
      "**Example `curl` Request:**\n"
     ]
    }
   ],
   "source": [
    "# Load the necessary context files\n",
    "prd_content = load_artifact(\"artifacts/day1_prd_2025-10-28_14-03-52.md\")\n",
    "api_code = load_artifact(\"app/main.py\")\n",
    "\n",
    "readme_prompt = f\"\"\"\n",
    "You are a technical writer creating a comprehensive README.md file for a new open-source project.\n",
    "\n",
    "Use the provided Product Requirements Document (PRD) for high-level context and the FastAPI source code for technical implementation details.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "**API Source Code:**\n",
    "<code>\n",
    "{api_code}\n",
    "</code>\n",
    "\n",
    "Generate a complete README.md file in GitHub-flavored Markdown format with the following sections:\n",
    "\n",
    "1. **Project Title** - Extract the project name from the PRD and create an engaging title\n",
    "2. **Overview** - Summarize the project's purpose, problem it solves, and target users based on the PRD content\n",
    "3. **Features** - List the key functionalities and capabilities derived from both the PRD and the API endpoints\n",
    "4. **API Endpoints** - Document each available API route with:\n",
    "   - HTTP method and path\n",
    "   - Brief description of functionality\n",
    "   - Practical `curl` examples for testing each endpoint\n",
    "   - Include JSON request bodies for POST/PUT endpoints using the Pydantic models from the code\n",
    "5. **Setup and Installation** - Provide step-by-step instructions including:\n",
    "   - Prerequisites (Python version, dependencies)\n",
    "   - Virtual environment setup\n",
    "   - Installing requirements\n",
    "   - Database setup (if applicable)\n",
    "   - Running the FastAPI server with uvicorn\n",
    "\n",
    "Ensure the README is professional, well-structured, and provides everything a developer needs to understand and run the project locally. Use proper Markdown formatting including code blocks, headers, and lists.\n",
    "\n",
    "Output only the raw Markdown content for the README.md file.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Project README ---\")\n",
    "if prd_content and api_code:\n",
    "    readme_content = get_completion(readme_prompt, client, model_name, api_provider)\n",
    "    cleaned_readme = clean_llm_output(readme_content, language='markdown')\n",
    "    print(cleaned_readme)\n",
    "    save_artifact(cleaned_readme, \"README.md\")\n",
    "else:\n",
    "    print(\"Skipping README generation because PRD or API code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to perform two of the most valuable code quality tasks: refactoring and documentation. You've seen how AI can help transform messy code into a clean, maintainable structure and how it can generate comprehensive documentation from high-level project artifacts and source code. These skills are a massive productivity multiplier for any development team.\n",
    "\n",
    "> **Key Takeaway:** LLMs excel at understanding and generating structured text, whether that structure is code or documentation. Providing a clear 'before' state (the bad code) and a clear goal (the refactoring principles) allows the AI to perform complex code transformation and documentation tasks efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
