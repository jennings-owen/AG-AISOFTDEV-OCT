{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4 - Lab 1: Automated Testing & Quality Assurance\n",
    "\n",
    "**Objective:** Generate a comprehensive `pytest` test suite for the database-connected FastAPI application, including tests for happy paths, edge cases, and tests that use advanced fixtures for database isolation.\n",
    "\n",
    "**Estimated Time:** 135 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 4! An application without tests is an application that is broken by design. Today, we focus on quality assurance. You will act as a QA Engineer, using an AI co-pilot to build a robust test suite for the API you created yesterday. This is a critical step to ensure our application is reliable and ready for production.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the source code for our main application from `app/main.py`. Providing the full code as context is essential for the LLM to generate accurate and relevant tests.\n",
    "\n",
    "**Model Selection:**\n",
    "For generating tests, models with strong code understanding and logical reasoning are best. `gpt-4.1`, `o3`, `codex-mini`, and `gemini-2.5-pro` are all excellent choices for this task.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read our application's source code.\n",
    "- `save_artifact()`: To save the generated test files.\n",
    "- `clean_llm_output()`: To clean up the generated Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 12:00:04,005 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4.1 latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")\n",
    "\n",
    "# Load the application code from Day 3 to provide context for test generation\n",
    "app_code = load_artifact(\"app/main.py\")\n",
    "if not app_code:\n",
    "    print(\"Warning: Could not load app/main.py. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating \"Happy Path\" Tests\n",
    "\n",
    "**Task:** Generate basic `pytest` tests for the ideal or \"happy path\" scenarios of your CRUD endpoints.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that asks the LLM to act as a QA Engineer.\n",
    "2.  Provide the `app_code` as context.\n",
    "3.  Instruct the LLM to generate a `pytest` test function for the `POST /users/` endpoint, asserting that a user is created successfully (e.g., checking for a `201 Created` or `200 OK` status code and verifying the response body).\n",
    "4.  Generate another test for the `GET /users/` endpoint.\n",
    "5.  Save the generated tests into a file named `tests/test_main_simple.py`.\n",
    "\n",
    "**Expected Quality:** A Python script containing valid `pytest` functions that test the basic, successful operation of your API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Happy Path Tests ---\n",
      "# test_main.py\n",
      "\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "# Before importing the app use the code:\n",
      "import sys\n",
      "import os\n",
      "\n",
      "# Ensure the current directory is in sys.path to import main.py\n",
      "sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\n",
      "\n",
      "from main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "\n",
      "def test_root_returns_404():\n",
      "    \"\"\"Test that GET / returns 404 since no root endpoint exists.\"\"\"\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 404\n",
      "\n",
      "def test_post_users_create_minimal():\n",
      "    \"\"\"Test creating a user with minimal required fields.\"\"\"\n",
      "    data = {\"email\": \"minimal@example.com\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"id\"] > 0\n",
      "    assert \"created_at\" in user\n",
      "    assert \"updated_at\" in user\n",
      "\n",
      "def test_post_users_create_full():\n",
      "    \"\"\"Test creating a user with all fields.\"\"\"\n",
      "    data = {\"email\": \"full@example.com\", \"full_name\": \"Full Name\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"full_name\"] == data[\"full_name\"]\n",
      "    assert user[\"id\"] > 0\n",
      "\n",
      "def test_post_users_unique_email():\n",
      "    \"\"\"Test that creating a user with a unique email works.\"\"\"\n",
      "    data = {\"email\": \"unique@example.com\", \"full_name\": \"Unique User\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"full_name\"] == data[\"full_name\"]\n",
      "\n",
      "def test_get_users_empty():\n",
      "    \"\"\"Test getting users when at least one user exists.\"\"\"\n",
      "    # Create a user first (should already exist from previous tests, but ensure it)\n",
      "    email = \"getusers1@example.com\"\n",
      "    client.post(\"/users/\", json={\"email\": email, \"full_name\": \"Get User\"})\n",
      "    response = client.get(\"/users/\")\n",
      "    assert response.status_code == 200\n",
      "    users = response.json()\n",
      "    assert isinstance(users, list)\n",
      "    assert any(u[\"email\"] == email for u in users)\n",
      "\n",
      "def test_get_users_pagination():\n",
      "    \"\"\"Test retrieving users with skip and limit.\"\"\"\n",
      "    # Create two users\n",
      "    client.post(\"/users/\", json={\"email\": \"paga@example.com\"})\n",
      "    client.post(\"/users/\", json={\"email\": \"pagb@example.com\"})\n",
      "    # Get only one (limit=1)\n",
      "    resp = client.get(\"/users/?limit=1\")\n",
      "    assert resp.status_code == 200\n",
      "    users = resp.json()\n",
      "    assert len(users) == 1\n",
      "    # Get with skip\n",
      "    resp = client.get(\"/users/?skip=1&limit=2\")\n",
      "    assert resp.status_code == 200\n",
      "    users = resp.json()\n",
      "    assert isinstance(users, list)\n",
      "\n",
      "def test_get_user_by_id():\n",
      "    \"\"\"Test retrieving a single user by ID.\"\"\"\n",
      "    # Create a user and then retrieve by id\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"byid@example.com\", \"full_name\": \"By Id\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    get_resp = client.get(f\"/users/{user_id}\")\n",
      "    assert get_resp.status_code == 200\n",
      "    user = get_resp.json()\n",
      "    assert user[\"id\"] == user_id\n",
      "    assert user[\"email\"] == \"byid@example.com\"\n",
      "\n",
      "def test_patch_users_update_email():\n",
      "    \"\"\"Test updating a user's email successfully.\"\"\"\n",
      "    # Create a user\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"update1@example.com\", \"full_name\": \"Update Me\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    # Update email\n",
      "    update_resp = client.patch(f\"/users/{user_id}\", json={\"email\": \"updatedemail@example.com\"})\n",
      "    assert update_resp.status_code == 200\n",
      "    user = update_resp.json()\n",
      "    assert user[\"email\"] == \"updatedemail@example.com\"\n",
      "    assert user[\"id\"] == user_id\n",
      "\n",
      "def test_patch_users_update_full_name():\n",
      "    \"\"\"Test updating a user's full_name successfully.\"\"\"\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"update2@example.com\", \"full_name\": \"Old Name\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    update_resp = client.patch(f\"/users/{user_id}\", json={\"full_name\": \"New Name\"})\n",
      "    assert update_resp.status_code == 200\n",
      "    user = update_resp.json()\n",
      "    assert user[\"full_name\"] == \"New Name\"\n",
      "\n",
      "def test_delete_users_delete_user():\n",
      "    \"\"\"Test deleting a user by ID.\"\"\"\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"deleteuser@example.com\", \"full_name\": \"Delete Me\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    delete_resp = client.delete(f\"/users/{user_id}\")\n",
      "    assert delete_resp.status_code == 200\n",
      "    assert delete_resp.json() == {\"detail\": \"User deleted successfully\"}\n",
      "    # Ensure user is deleted\n",
      "    get_resp = client.get(f\"/users/{user_id}\")\n",
      "    assert get_resp.status_code == 404\n"
     ]
    }
   ],
   "source": [
    "happy_path_tests_prompt = f\"\"\"\n",
    "Act as a QA engineer. Given the following Python FastAPI application code, generate comprehensive happy path tests using the pytest framework and the TestClient from fastapi.testclient. Ensure that each test function is clearly named to reflect the endpoint and scenario being tested. Include necessary imports and setup code for the TestClient.\n",
    "\n",
    "Use the naming convention 'test_<endpoint>_<scenario>' for test functions. Focus on testing successful interactions with the API endpoints, including valid inputs and expected outputs.\n",
    "\n",
    "Here is the application code:\n",
    "{app_code}\n",
    "\n",
    "Specific tests to include:\n",
    "1. Test the root endpoint (GET /) to ensure it returns a 200 status code\n",
    "2. Test `POST /users/` endpoint extensively, asserting that a user is created successfully (e.g., checking for a `201 Created` or `200 OK` status code and verifying the response body).\n",
    "3. Generate a test for the `GET /users/` endpoint.\n",
    "\n",
    "Write a minimum of 10 happy path test cases covering the above endpoints.\n",
    "Before importing the app use the code: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Happy Path Tests ---\")\n",
    "if app_code:\n",
    "    generated_happy_path_tests = get_completion(happy_path_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_tests = clean_llm_output(generated_happy_path_tests, language='python')\n",
    "    print(cleaned_tests)\n",
    "    save_artifact(cleaned_tests, \"tests/test_main_simple.py\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Edge Case Tests\n",
    "\n",
    "**Task:** Prompt the LLM to generate tests for common edge cases, such as providing invalid data or requesting a non-existent resource.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide the `app_code` as context.\n",
    "3.  Instruct the LLM to write two new test functions:\n",
    "    * A test for the `POST /users/` endpoint that tries to create a user with an email that already exists, asserting that the API returns a `400 Bad Request` error.\n",
    "    * A test for the `GET /users/{user_id}` endpoint that requests a non-existent user ID, asserting that the API returns a `404 Not Found` error.\n",
    "\n",
    "**Expected Quality:** Two new `pytest` functions that verify the application handles common error scenarios correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Edge Case Tests ---\n",
      "# test_main.py\n",
      "\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "from main import app, Base, engine\n",
      "\n",
      "# --- Pytest Fixtures for DB Isolation ---\n",
      "\n",
      "@pytest.fixture(autouse=True, scope=\"function\")\n",
      "def setup_database():\n",
      "    # Drop and recreate all tables before each test function for clean state\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "    yield\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "# --- Tests ---\n",
      "\n",
      "def test_root_endpoint_with_invalid_query_params():\n",
      "    \"\"\"\n",
      "    Test GET / (root) with invalid query parameters.\n",
      "    Should return 404 since root endpoint does not exist, regardless of params.\n",
      "    \"\"\"\n",
      "    response = client.get(\"/\", params={\"foo\": \"bar\", \"invalid\": 123})\n",
      "    assert response.status_code == 404\n",
      "    assert response.json()[\"detail\"] == \"Not Found\"\n",
      "\n",
      "def test_post_users_missing_required_fields():\n",
      "    \"\"\"\n",
      "    Test POST /users/ with missing required fields.\n",
      "    Should return 422 Unprocessable Entity.\n",
      "    \"\"\"\n",
      "    # 'email' is required, so omit it\n",
      "    user_data = {\n",
      "        \"full_name\": \"John Doe\"\n",
      "    }\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "    assert response.status_code == 422\n",
      "    # The error should mention 'email'\n",
      "    assert any(\n",
      "        err[\"loc\"][-1] == \"email\"\n",
      "        for err in response.json()[\"detail\"]\n",
      "    )\n",
      "\n",
      "def test_post_users_invalid_email_format():\n",
      "    \"\"\"\n",
      "    Test POST /users/ with invalid email format.\n",
      "    Should return 422 Unprocessable Entity.\n",
      "    \"\"\"\n",
      "    user_data = {\n",
      "        \"email\": \"not-an-email\",\n",
      "        \"full_name\": \"Jane Doe\"\n",
      "    }\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "    assert response.status_code == 422\n",
      "    # The error should mention 'email'\n",
      "    assert any(\n",
      "        err[\"loc\"][-1] == \"email\"\n",
      "        for err in response.json()[\"detail\"]\n",
      "    )\n",
      "\n",
      "def test_post_users_duplicate_email():\n",
      "    \"\"\"\n",
      "    Test POST /users/ with duplicate email (email already registered).\n",
      "    Should return 400 Bad Request.\n",
      "    \"\"\"\n",
      "    user_data = {\n",
      "        \"email\": \"user@example.com\",\n",
      "        \"full_name\": \"First User\"\n",
      "    }\n",
      "    # Create first user\n",
      "    client.post(\"/users/\", json=user_data)\n",
      "    # Attempt to create second user with same email\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "    assert response.status_code == 400\n",
      "    assert response.json()[\"detail\"] == \"Email already registered\"\n",
      "\n",
      "def test_get_users_user_id_not_found():\n",
      "    \"\"\"\n",
      "    Test GET /users/{user_id} with an ID that does not exist.\n",
      "    Should return 404 Not Found.\n",
      "    \"\"\"\n",
      "    response = client.get(\"/users/99999\")\n",
      "    assert response.status_code == 404\n",
      "    assert response.json()[\"detail\"] == \"User not found\"\n",
      "\n",
      "# --- Additional Edge Case Example ---\n",
      "\n",
      "def test_patch_users_update_nonexistent_user():\n",
      "    \"\"\"\n",
      "    Test PATCH /users/{user_id} for a user that does not exist.\n",
      "    Should return 404 Not Found.\n",
      "    \"\"\"\n",
      "    response = client.patch(\"/users/12345\", json={\"full_name\": \"Ghost User\"})\n",
      "    assert response.status_code == 404\n",
      "    assert response.json()[\"detail\"] == \"User not found\"\n"
     ]
    }
   ],
   "source": [
    "edge_case_tests_prompt = f\"\"\"\n",
    "Act as a QA engineer. Given the following Python FastAPI application code, generate comprehensive edge case tests using the pytest framework and the TestClient from fastapi.testclient. Ensure that each test function is clearly named to reflect the endpoint and scenario being tested. Include necessary imports and setup code for the TestClient.\n",
    "\n",
    "Use the naming convention 'test_<endpoint>_<scenario>' for test functions. Focus on testing edge cases and potential failure points in the API endpoints.\n",
    "\n",
    "Here is the application code:\n",
    "{app_code}\n",
    "\n",
    "Specific tests to include:\n",
    "1. Test the root endpoint (GET /) with invalid query parameters to ensure it handles errors gracefully.\n",
    "2. Test `POST /users/` endpoint with missing required fields, asserting that it returns a 422 Unprocessable Entity status code.\n",
    "3. Test `GET /users/` endpoint with an invalid user ID, ensuring it returns a 404 Not Found status code.\n",
    "\n",
    "Write a minimum of 5 edge case test cases covering the above endpoints.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Edge Case Tests ---\")\n",
    "if app_code:\n",
    "    generated_edge_case_tests = get_completion(edge_case_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_edge_case_tests = clean_llm_output(generated_edge_case_tests, language='python')\n",
    "    print(cleaned_edge_case_tests)\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Testing with an Isolated Database Fixture\n",
    "\n",
    "**Task:** Generate a `pytest` fixture that creates a fresh, isolated, in-memory database for each test session. Then, refactor your tests to use this fixture. This is a critical pattern for professional-grade testing.\n",
    "\n",
    "> **Hint:** Why use an isolated database? Running tests against your actual development database can lead to data corruption and flaky, unreliable tests. A pytest fixture that creates a fresh, in-memory database for each test ensures that your tests are independent, repeatable, and have no side effects.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that asks the LLM to generate a `pytest` fixture.\n",
    "2.  This fixture should configure a temporary, in-memory SQLite database using SQLAlchemy.\n",
    "3.  It needs to create all the database tables before the test runs and tear them down afterward.\n",
    "4.  Crucially, it must override the `get_db` dependency in your FastAPI app to use this temporary database during tests.\n",
    "5.  Save the generated fixture code to a special file named `tests/conftest.py`.\n",
    "6.  Finally, create a new test file, `tests/test_main_with_fixture.py`, and ask the LLM to rewrite the happy-path tests from Challenge 1 to use the new database fixture.\n",
    "\n",
    "**Expected Quality:** Two new files, `tests/conftest.py` and `tests/test_main_with_fixture.py`, containing a professional `pytest` fixture for database isolation and tests that are correctly refactored to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Pytest DB Fixture ---\n",
      "# conftest.py\n",
      "\n",
      "import pytest\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "from main import app, Base, get_db, User\n",
      "\n",
      "# ---- Test Database Fixture ----\n",
      "\n",
      "@pytest.fixture\n",
      "def test_db():\n",
      "    # 1. Create a new in-memory SQLite engine and sessionmaker\n",
      "    engine = create_engine(\"sqlite:///:memory:\", connect_args={\"check_same_thread\": False})\n",
      "    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "\n",
      "    # 2. Create all tables\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    # 3. Optionally, seed initial data\n",
      "    # Example: create a test user\n",
      "    with TestingSessionLocal() as session:\n",
      "        user = User(email=\"seed@example.com\", full_name=\"Seed User\")\n",
      "        session.add(user)\n",
      "        session.commit()\n",
      "\n",
      "    # 4. Provide a fresh session for each test\n",
      "    def override_get_db():\n",
      "        db = TestingSessionLocal()\n",
      "        try:\n",
      "            yield db\n",
      "        finally:\n",
      "            db.close()\n",
      "\n",
      "    # 5. Override the app's get_db dependency\n",
      "    app.dependency_overrides[get_db] = override_get_db\n",
      "\n",
      "    yield TestingSessionLocal\n",
      "\n",
      "    # 6. Teardown: Drop all tables and dispose engine\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "    engine.dispose()\n",
      "    app.dependency_overrides.clear()\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def client(test_db):\n",
      "    \"\"\"\n",
      "    Provides a FastAPI TestClient that uses the isolated test database.\n",
      "    \"\"\"\n",
      "    with TestClient(app) as c:\n",
      "        yield c\n",
      "\n",
      "--- Generating Refactored Tests ---\n",
      "# test_main.py\n",
      "\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker, Session\n",
      "\n",
      "import sys\n",
      "import os\n",
      "\n",
      "# Ensure the current directory is in sys.path to import main.py\n",
      "sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))\n",
      "\n",
      "from main import app, Base, get_db\n",
      "\n",
      "# -------------------------\n",
      "# Pytest fixture for test DB\n",
      "# -------------------------\n",
      "\n",
      "@pytest.fixture\n",
      "def db_session():\n",
      "    \"\"\"Creates a new database session for a test with an isolated in-memory SQLite DB.\"\"\"\n",
      "    # Use a unique in-memory database for each test\n",
      "    TEST_SQLALCHEMY_DATABASE_URL = \"sqlite:///:memory:\"\n",
      "\n",
      "    # Create engine and sessionmaker bound to it\n",
      "    engine = create_engine(\n",
      "        TEST_SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False}\n",
      "    )\n",
      "    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "\n",
      "    # Create all tables in the in-memory database\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    # Create a new session for this test\n",
      "    db = TestingSessionLocal()\n",
      "\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "        # Drop all tables at the end of the test for extra isolation\n",
      "        Base.metadata.drop_all(bind=engine)\n",
      "\n",
      "@pytest.fixture\n",
      "def client(db_session):\n",
      "    \"\"\"\n",
      "    Yields a TestClient with the app's get_db dependency overridden to use the test session.\n",
      "    \"\"\"\n",
      "    # Override FastAPI's get_db dependency to use the test session\n",
      "    def override_get_db():\n",
      "        try:\n",
      "            yield db_session\n",
      "        finally:\n",
      "            pass  # db_session fixture manages close\n",
      "\n",
      "    app.dependency_overrides[get_db] = override_get_db\n",
      "\n",
      "    with TestClient(app) as c:\n",
      "        yield c\n",
      "\n",
      "    # Clean up the override\n",
      "    app.dependency_overrides.clear()\n",
      "\n",
      "# -------------------------\n",
      "#      Tests\n",
      "# -------------------------\n",
      "\n",
      "def test_root_returns_404(client):\n",
      "    \"\"\"Test that GET / returns 404 since no root endpoint exists.\"\"\"\n",
      "    response = client.get(\"/\")\n",
      "    assert response.status_code == 404\n",
      "\n",
      "def test_post_users_create_minimal(client):\n",
      "    \"\"\"Test creating a user with minimal required fields.\"\"\"\n",
      "    data = {\"email\": \"minimal@example.com\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"id\"] > 0\n",
      "    assert \"created_at\" in user\n",
      "    assert \"updated_at\" in user\n",
      "\n",
      "def test_post_users_create_full(client):\n",
      "    \"\"\"Test creating a user with all fields.\"\"\"\n",
      "    data = {\"email\": \"full@example.com\", \"full_name\": \"Full Name\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"full_name\"] == data[\"full_name\"]\n",
      "    assert user[\"id\"] > 0\n",
      "\n",
      "def test_post_users_unique_email(client):\n",
      "    \"\"\"Test that creating a user with a unique email works.\"\"\"\n",
      "    data = {\"email\": \"unique@example.com\", \"full_name\": \"Unique User\"}\n",
      "    response = client.post(\"/users/\", json=data)\n",
      "    assert response.status_code == 201\n",
      "    user = response.json()\n",
      "    assert user[\"email\"] == data[\"email\"]\n",
      "    assert user[\"full_name\"] == data[\"full_name\"]\n",
      "\n",
      "def test_post_users_duplicate_email_fails(client):\n",
      "    \"\"\"Test that creating a user with a duplicate email fails.\"\"\"\n",
      "    data = {\"email\": \"dup@example.com\"}\n",
      "    response1 = client.post(\"/users/\", json=data)\n",
      "    assert response1.status_code == 201\n",
      "    response2 = client.post(\"/users/\", json=data)\n",
      "    assert response2.status_code == 400\n",
      "    assert response2.json()[\"detail\"] == \"Email already registered\"\n",
      "\n",
      "def test_get_users_empty(client):\n",
      "    \"\"\"Test getting users when at least one user exists.\"\"\"\n",
      "    # Initially, should be empty\n",
      "    response = client.get(\"/users/\")\n",
      "    assert response.status_code == 200\n",
      "    assert response.json() == []\n",
      "    # Create a user\n",
      "    email = \"getusers1@example.com\"\n",
      "    client.post(\"/users/\", json={\"email\": email, \"full_name\": \"Get User\"})\n",
      "    response = client.get(\"/users/\")\n",
      "    assert response.status_code == 200\n",
      "    users = response.json()\n",
      "    assert isinstance(users, list)\n",
      "    assert any(u[\"email\"] == email for u in users)\n",
      "\n",
      "def test_get_users_pagination(client):\n",
      "    \"\"\"Test retrieving users with skip and limit.\"\"\"\n",
      "    # Create two users\n",
      "    client.post(\"/users/\", json={\"email\": \"paga@example.com\"})\n",
      "    client.post(\"/users/\", json={\"email\": \"pagb@example.com\"})\n",
      "    # Get only one (limit=1)\n",
      "    resp = client.get(\"/users/?limit=1\")\n",
      "    assert resp.status_code == 200\n",
      "    users = resp.json()\n",
      "    assert len(users) == 1\n",
      "    # Get with skip\n",
      "    resp = client.get(\"/users/?skip=1&limit=2\")\n",
      "    assert resp.status_code == 200\n",
      "    users = resp.json()\n",
      "    assert isinstance(users, list)\n",
      "    # There should be one user after skipping 1\n",
      "    assert len(users) == 1\n",
      "\n",
      "def test_get_user_by_id(client):\n",
      "    \"\"\"Test retrieving a single user by ID.\"\"\"\n",
      "    # Create a user and then retrieve by id\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"byid@example.com\", \"full_name\": \"By Id\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    get_resp = client.get(f\"/users/{user_id}\")\n",
      "    assert get_resp.status_code == 200\n",
      "    user = get_resp.json()\n",
      "    assert user[\"id\"] == user_id\n",
      "    assert user[\"email\"] == \"byid@example.com\"\n",
      "\n",
      "def test_get_user_by_id_not_found(client):\n",
      "    \"\"\"Test retrieving a non-existent user returns 404.\"\"\"\n",
      "    get_resp = client.get(\"/users/9999\")\n",
      "    assert get_resp.status_code == 404\n",
      "\n",
      "def test_patch_users_update_email(client):\n",
      "    \"\"\"Test updating a user's email successfully.\"\"\"\n",
      "    # Create a user\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"update1@example.com\", \"full_name\": \"Update Me\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    # Update email\n",
      "    update_resp = client.patch(f\"/users/{user_id}\", json={\"email\": \"updatedemail@example.com\"})\n",
      "    assert update_resp.status_code == 200\n",
      "    user = update_resp.json()\n",
      "    assert user[\"email\"] == \"updatedemail@example.com\"\n",
      "    assert user[\"id\"] == user_id\n",
      "\n",
      "def test_patch_users_update_full_name(client):\n",
      "    \"\"\"Test updating a user's full_name successfully.\"\"\"\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"update2@example.com\", \"full_name\": \"Old Name\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    update_resp = client.patch(f\"/users/{user_id}\", json={\"full_name\": \"New Name\"})\n",
      "    assert update_resp.status_code == 200\n",
      "    user = update_resp.json()\n",
      "    assert user[\"full_name\"] == \"New Name\"\n",
      "\n",
      "def test_patch_user_not_found(client):\n",
      "    \"\"\"Test updating a non-existent user returns 404.\"\"\"\n",
      "    update_resp = client.patch(\"/users/9999\", json={\"email\": \"doesnotexist@example.com\"})\n",
      "    assert update_resp.status_code == 404\n",
      "\n",
      "def test_delete_users_delete_user(client):\n",
      "    \"\"\"Test deleting a user by ID.\"\"\"\n",
      "    resp = client.post(\"/users/\", json={\"email\": \"deleteuser@example.com\", \"full_name\": \"Delete Me\"})\n",
      "    user_id = resp.json()[\"id\"]\n",
      "    delete_resp = client.delete(f\"/users/{user_id}\")\n",
      "    assert delete_resp.status_code == 200\n",
      "    assert delete_resp.json() == {\"detail\": \"User deleted successfully\"}\n",
      "    # Ensure user is deleted\n",
      "    get_resp = client.get(f\"/users/{user_id}\")\n",
      "    assert get_resp.status_code == 404\n",
      "\n",
      "def test_delete_user_not_found(client):\n",
      "    \"\"\"Test deleting a non-existent user returns 404.\"\"\"\n",
      "    delete_resp = client.delete(\"/users/9999\")\n",
      "    assert delete_resp.status_code == 404\n"
     ]
    }
   ],
   "source": [
    "db_fixture_prompt = f\"\"\"\n",
    "Act as a QA engineer. Given the following Python FastAPI application code, generate a pytest fixture for an isolated test database using the SQLAlchemy and pytest libraries. Ensure that the fixture provides a clean database state for each test and includes necessary setup and teardown code. The database should be an in-memory SQLite database for testing purposes. Critically, ensure that all database tables are created and seeded before each test runs, and that the database is properly disposed of after each test to prevent state leakage between tests.\n",
    "\n",
    "You must override the get_db dependency in the FastAPI app to use this test database within the fixture during the tests.\n",
    "\n",
    "Here is the application code:\n",
    "{app_code}\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Pytest DB Fixture ---\")\n",
    "if app_code:\n",
    "    generated_db_fixture = get_completion(db_fixture_prompt, client, model_name, api_provider)\n",
    "    cleaned_fixture = clean_llm_output(generated_db_fixture, language='python')\n",
    "    print(cleaned_fixture)\n",
    "    save_artifact(cleaned_fixture, \"tests/conftest.py\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping fixture generation because app context is missing.\")\n",
    "\n",
    "\n",
    "refactor_tests_prompt = f\"\"\"\n",
    "Act as a QA engineer. Given the following Python FastAPI application code and existing test cases, refactor the tests to utilize a pytest fixture for an isolated test database. Ensure that the refactored tests use the fixture to obtain a clean database state for each test, and that they properly interact with the FastAPI app's overridden get_db dependency.\n",
    "\n",
    "Here is the application code:\n",
    "{app_code}\n",
    "\n",
    "Here are the existing test cases to refactor:\n",
    "{cleaned_tests}\n",
    "\n",
    "Refactor the above test cases to use the database fixture for setup and teardown, ensuring that each test runs in isolation with a fresh database state.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Generating Refactored Tests ---\")\n",
    "if app_code:\n",
    "    refactored_tests = get_completion(refactor_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_refactored_tests = clean_llm_output(refactored_tests, language='python')\n",
    "    print(cleaned_refactored_tests)\n",
    "    save_artifact(cleaned_refactored_tests, \"tests/test_main_with_fixture.py\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping test refactoring because app context is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Fantastic work! You have built a comprehensive test suite for your API, moving from simple happy path tests to advanced, isolated database testing. You've learned how to use AI to brainstorm edge cases and generate complex fixtures. Having a strong test suite like this gives you the confidence to make changes to your application without fear of breaking existing functionality.\n",
    "\n",
    "> **Key Takeaway:** Using AI to generate tests is a massive force multiplier for quality assurance. It excels at creating boilerplate test code, brainstorming edge cases, and generating complex setup fixtures, allowing developers to build more reliable software faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
