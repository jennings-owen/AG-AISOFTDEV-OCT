{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents: A Deep Dive\n",
    "\n",
    "**Objective:** This notebook provides a detailed walkthrough of building powerful, single agents using LangChain. While the course's Day 5 lab introduced the basics, this session focuses on the internal mechanics, advanced tool creation, and state management to give you a deeper understanding of how to build and debug robust LangChain agents.\n",
    "\n",
    "**Target Audience:** Software engineers attending the AI-Driven Software Engineering Program.\n",
    "\n",
    "**Core Concepts Covered:**\n",
    "1.  **Review of Agent Fundamentals:** A quick recap of the `AgentExecutor` and the ReAct (Reason+Act) loop.\n",
    "2.  **Custom Tools in Detail:** Mastering the `@tool` decorator and understanding why a good docstring is the most critical part of a tool.\n",
    "3.  **Agent State & Memory:** Giving your agent conversational memory to handle multi-turn interactions.\n",
    "4.  **Debugging Agent Behavior:** Using `verbose=True` to interpret the agent's thought process and fix issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we'll install the necessary libraries and set up our environment by loading the required API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\") or not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print(\"ERROR: API keys not found. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review of Agent Fundamentals\n",
    "\n",
    "Let's quickly recap the core components of a LangChain agent from the Day 5 lab. An agent consists of:\n",
    "\n",
    "- **LLM:** The language model that acts as the agent's \"brain.\"\n",
    "- **Tools:** Functions the agent can call to interact with the outside world (e.g., search, calculators, file readers).\n",
    "- **Prompt Template:** A template that structures the input to the LLM, telling it its persona, the tools it has, and the user's request. It critically includes an `agent_scratchpad` for the ReAct loop.\n",
    "- **Agent Executor:** The runtime environment that orchestrates the **Thought -> Action -> Observation** loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labadmin\\AppData\\Local\\Temp\\2\\ipykernel_6592\\1963754524.py:7: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tools = [TavilySearchResults(max_results=1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recap: Agent with Web Search ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Apple Inc. market cap September 3 2025'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Apple Inc. (AAPL) Stock Historical Prices & Data - Yahoo Finance', 'url': 'https://finance.yahoo.com/quote/AAPL/history/', 'content': '| Sep 4, 2025 | 238.45 | 239.90 | 236.74 | 239.78 | 239.78 | 47,549,400 |\\n| Sep 3, 2025 | 237.21 | 238.85 | 234.36 | 238.47 | 238.47 | 66,427,800 |\\n| Sep 2, 2025 | 229.25 | 230.85 | 226.97 | 229.72 | 229.72 | 44,075,600 |\\n| Aug 29, 2025 | 232.51 | 233.38 | 231.37 | 232.14 | 232.14 | 39,418,400 |\\n| Aug 28, 2025 | 230.82 | 233.41 | 229.34 | 232.56 | 232.56 | 38,074,700 |\\n| Aug 27, 2025 | 228.61 | 230.90 | 228.26 | 230.49 | 230.49 | 31,259,500 | [...] | Sep 12, 2025 | 229.22 | 234.51 | 229.02 | 234.07 | 234.07 | 55,824,200 |\\n| Sep 11, 2025 | 226.88 | 230.45 | 226.65 | 230.03 | 230.03 | 50,208,600 |\\n| Sep 10, 2025 | 232.19 | 232.42 | 225.95 | 226.79 | 226.79 | 83,440,800 |\\n| Sep 9, 2025 | 237.00 | 238.78 | 233.36 | 234.35 | 234.35 | 66,313,900 |\\n| Sep 8, 2025 | 239.30 | 240.15 | 236.34 | 237.88 | 237.88 | 48,999,500 |\\n| Sep 5, 2025 | 240.00 | 241.32 | 238.49 | 239.69 | 239.69 | 54,870,400 | [...] | Sep 30, 2025 | 254.86 | 255.92 | 253.11 | 254.63 | 254.63 | 37,704,300 |\\n| Sep 29, 2025 | 254.56 | 255.00 | 253.01 | 254.43 | 254.43 | 40,127,700 |\\n| Sep 26, 2025 | 254.10 | 257.60 | 253.78 | 255.46 | 255.46 | 46,076,300 |\\n| Sep 25, 2025 | 253.21 | 257.17 | 251.71 | 256.87 | 256.87 | 55,202,100 |\\n| Sep 24, 2025 | 255.22 | 255.74 | 251.04 | 252.31 | 252.31 | 42,303,700 |\\n| Sep 23, 2025 | 255.88 | 257.34 | 253.58 | 254.43 | 254.43 | 60,275,200 |', 'score': 0.9053309}]\u001b[0m\u001b[32;1m\u001b[1;3mAs of September 3, 2025, Apple Inc.'s stock closed at $238.47. To determine the market capitalization, we would typically multiply the closing stock price by the total number of outstanding shares. Since the total number of outstanding shares is not provided in this data, the precise market cap cannot be calculated directly from this information. You would need the number of outstanding shares to find the exact market cap.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the market cap of Apple Inc. as of September 3 2025?',\n",
       " 'output': \"As of September 3, 2025, Apple Inc.'s stock closed at $238.47. To determine the market capitalization, we would typically multiply the closing stock price by the total number of outstanding shares. Since the total number of outstanding shares is not provided in this data, the precise market cap cannot be calculated directly from this information. You would need the number of outstanding shares to find the exact market cap.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain import hub\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"--- Recap: Agent with Web Search ---\")\n",
    "agent_executor.invoke({\"input\": \"What is the market cap of Apple Inc. as of September 3 2025?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Tools in Detail\n",
    "\n",
    "The real power of LangChain agents comes from giving them custom tools to interact with your specific data or APIs. The `@tool` decorator is the easiest way to do this.\n",
    "\n",
    "**The Golden Rule of Tools:** The agent **does not see your Python code**. It only sees the function name, its arguments (and their type hints), and the **docstring**. A clear, descriptive docstring is the most important piece of prompt engineering you can do for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing the Calculator Tool ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `simple_calculator` with `{'expression': '125*8'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1000\u001b[0m\u001b[32;1m\u001b[1;3m125 multiplied by 8 is 1000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Testing the File Reader Tool ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `read_file_content` with `{'filename': 'project_status.txt'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mThe project is on track. The next milestone is the agent evaluation phase.\u001b[0m\u001b[32;1m\u001b[1;3mThe project is on track. The next milestone is the agent evaluation phase.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What is the status of the project based on the 'project_status.txt' file?\",\n",
       " 'output': 'The project is on track. The next milestone is the agent evaluation phase.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "import json\n",
    "\n",
    "# A simple custom tool\n",
    "@tool\n",
    "def simple_calculator(expression: str) -> str:\n",
    "    \"\"\"Calculates the result of a simple mathematical expression (e.g., '2+2', '10*5').\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# A tool that interacts with the local file system\n",
    "# In a real app, ensure this is secure and sandboxed!\n",
    "@tool\n",
    "def read_file_content(filename: str) -> str:\n",
    "    \"\"\"Reads the content of a specified file. Use this to get information from local files.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: File '{filename}' not found.\"\n",
    "\n",
    "# Create a new agent with multiple custom tools\n",
    "custom_tools = [simple_calculator, read_file_content]\n",
    "custom_agent = create_tool_calling_agent(llm, custom_tools, prompt)\n",
    "custom_executor = AgentExecutor(agent=custom_agent, tools=custom_tools, verbose=True)\n",
    "\n",
    "print(\"--- Testing the Calculator Tool ---\")\n",
    "custom_executor.invoke({\"input\": \"What is 125 multiplied by 8?\"})\n",
    "\n",
    "# Let's create a dummy file for the next test\n",
    "with open(\"project_status.txt\", \"w\") as f:\n",
    "    f.write(\"The project is on track. The next milestone is the agent evaluation phase.\")\n",
    "\n",
    "print(\"\\n--- Testing the File Reader Tool ---\")\n",
    "custom_executor.invoke({\"input\": \"What is the status of the project based on the 'project_status.txt' file?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent State & Memory\n",
    "\n",
    "By default, the `AgentExecutor` is stateless. Each call is independent. To have a conversation, we need to add a memory component. The easiest way is to include placeholders for chat history in the prompt and manage the history manually.\n",
    "\n",
    "LangChain's Expression Language (LCEL) makes this more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Conversation Turn 1 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `simple_calculator` with `{'expression': '500-120'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m380\u001b[0m\u001b[32;1m\u001b[1;3mYou have 380 left after spending 120 on a book from your budget of 500.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI: You have 380 left after spending 120 on a book from your budget of 500.\n",
      "\n",
      "--- Conversation Turn 2 (with memory) ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `simple_calculator` with `{'expression': '380 - 55'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m325\u001b[0m\u001b[32;1m\u001b[1;3mIf you spend another 55, you will have 325 remaining.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI: If you spend another 55, you will have 325 remaining.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# 1. Create a new prompt that includes a placeholder for chat history\n",
    "memory_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. You have access to a calculator.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# 2. Create the agent with the new prompt\n",
    "memory_tools = [simple_calculator]\n",
    "memory_agent = create_tool_calling_agent(llm, memory_tools, memory_prompt)\n",
    "memory_executor = AgentExecutor(agent=memory_agent, tools=memory_tools, verbose=True)\n",
    "\n",
    "# 3. Manage the chat history manually\n",
    "chat_history = []\n",
    "\n",
    "print(\"--- Conversation Turn 1 ---\")\n",
    "input1 = \"My budget is 500. I spent 120 on a book. How much is left?\"\n",
    "result1 = memory_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=input1),\n",
    "    AIMessage(content=result1[\"output\"]),\n",
    "])\n",
    "print(f\"\\nAI: {result1['output']}\")\n",
    "\n",
    "print(\"\\n--- Conversation Turn 2 (with memory) ---\")\n",
    "input2 = \"If I spend another 55, what is the remaining amount?\"\n",
    "result2 = memory_executor.invoke({\"input\": input2, \"chat_history\": chat_history})\n",
    "print(f\"\\nAI: {result2['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Debugging Agent Behavior\n",
    "\n",
    "The most important tool for debugging an agent is `verbose=True` in the `AgentExecutor`. This prints out the agent's internal monologue, showing you the **Thought -> Action -> Observation** loop in real-time.\n",
    "\n",
    "When an agent fails, look at the verbose output:\n",
    "-   **Thought:** What was the agent thinking? Did it misunderstand the goal?\n",
    "-   **Action:** Which tool did it choose? Were the parameters correct? If it didn't choose a tool when it should have, the tool's docstring might be unclear.\n",
    "-   **Observation:** What was the output of the tool? Was it an error? Was the format unexpected?\n",
    "\n",
    "Most agent failures can be traced back to a poorly worded prompt or an unclear tool docstring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "In this deep dive, you've reinforced your understanding of LangChain agents. You've seen how to create powerful, specialized agents by giving them custom tools and how to add memory for conversational context. Most importantly, you've learned how to debug agentic behavior by analyzing the ReAct loop.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- An agent's capabilities are defined by its tools.\n",
    "- A tool's docstring is its most important feature.\n",
    "- Conversational memory requires explicitly managing and passing chat history.\n",
    "- `verbose=True` is your best friend for debugging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
