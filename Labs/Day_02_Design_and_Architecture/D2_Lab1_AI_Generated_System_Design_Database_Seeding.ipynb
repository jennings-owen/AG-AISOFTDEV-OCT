{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 13:27:50,295 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd_2025-10-27_17-33-10.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n",
      "PRAGMA foreign_keys = ON;\n",
      "\n",
      "DROP TABLE IF EXISTS submission_feedback;\n",
      "DROP TABLE IF EXISTS task_submissions;\n",
      "DROP TABLE IF EXISTS resources;\n",
      "DROP TABLE IF EXISTS onboarding_tasks;\n",
      "DROP TABLE IF EXISTS learning_path_tasks;\n",
      "DROP TABLE IF EXISTS learning_paths;\n",
      "DROP TABLE IF EXISTS task_templates;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS roles;\n",
      "DROP TABLE IF EXISTS departments;\n",
      "\n",
      "CREATE TABLE departments (\n",
      "    department_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE roles (\n",
      "    role_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    description TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    full_name TEXT NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    sso_user_id TEXT UNIQUE,\n",
      "    role_id INTEGER NOT NULL,\n",
      "    department_id INTEGER,\n",
      "    manager_id INTEGER,\n",
      "    mentor_id INTEGER,\n",
      "    hire_date TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles (role_id) ON DELETE RESTRICT,\n",
      "    FOREIGN KEY (department_id) REFERENCES departments (department_id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY (manager_id) REFERENCES users (user_id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY (mentor_id) REFERENCES users (user_id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE task_templates (\n",
      "    task_template_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    task_type TEXT NOT NULL CHECK(task_type IN ('LEARNING_MODULE', 'HR_FORM', 'SIMULATED_PROJECT', 'GENERAL')),\n",
      "    estimated_duration_days INTEGER DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE learning_paths (\n",
      "    learning_path_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    role_id INTEGER UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles (role_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE learning_path_tasks (\n",
      "    learning_path_task_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    learning_path_id INTEGER NOT NULL,\n",
      "    task_template_id INTEGER NOT NULL,\n",
      "    sequence_order INTEGER NOT NULL,\n",
      "    FOREIGN KEY (learning_path_id) REFERENCES learning_paths (learning_path_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_template_id) REFERENCES task_templates (task_template_id) ON DELETE CASCADE,\n",
      "    UNIQUE (learning_path_id, task_template_id),\n",
      "    UNIQUE (learning_path_id, sequence_order)\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_tasks (\n",
      "    task_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    task_template_id INTEGER NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'PENDING' CHECK(status IN ('PENDING', 'IN_PROGRESS', 'COMPLETED', 'OVERDUE')),\n",
      "    due_date TEXT,\n",
      "    completed_at TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_template_id) REFERENCES task_templates (task_template_id) ON DELETE CASCADE,\n",
      "    UNIQUE(user_id, task_template_id)\n",
      ");\n",
      "\n",
      "CREATE TABLE resources (\n",
      "    resource_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    category TEXT,\n",
      "    resource_type TEXT NOT NULL CHECK(resource_type IN ('PDF', 'URL', 'DOCUMENT')),\n",
      "    storage_path_or_url TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE task_submissions (\n",
      "    submission_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    task_id INTEGER NOT NULL UNIQUE,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    submission_content TEXT,\n",
      "    storage_path TEXT,\n",
      "    submitted_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks (task_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE submission_feedback (\n",
      "    feedback_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    submission_id INTEGER NOT NULL,\n",
      "    reviewer_id INTEGER NOT NULL,\n",
      "    feedback_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (submission_id) REFERENCES task_submissions (submission_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (reviewer_id) REFERENCES users (user_id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_users_email ON users (email);\n",
      "CREATE INDEX idx_users_role_id ON users (role_id);\n",
      "CREATE INDEX idx_users_department_id ON users (department_id);\n",
      "CREATE INDEX idx_users_manager_id ON users (manager_id);\n",
      "CREATE INDEX idx_onboarding_tasks_user_id ON onboarding_tasks (user_id);\n",
      "CREATE INDEX idx_onboarding_tasks_status ON onboarding_tasks (status);\n",
      "CREATE INDEX idx_onboarding_tasks_due_date ON onboarding_tasks (due_date);\n",
      "CREATE INDEX idx_resources_title ON resources (title);\n",
      "CREATE INDEX idx_resources_category ON resources (category);\n",
      "CREATE INDEX idx_task_submissions_task_id ON task_submissions (task_id);\n",
      "CREATE INDEX idx_submission_feedback_submission_id ON submission_feedback (submission_id);\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a senior Database Administrator (DBA). Act only as the DBA and use the Product Requirements Document (PRD) below as the single source of truth. Do not invent features or behaviors that are not implied by the PRD.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "Task:\n",
    "Design a normalized, production-ready SQL schema for an onboarding tool based on the PRD above.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output must be SQLite-compatible SQL only.\n",
    "- Return raw SQL statements only (no explanatory text, no Markdown fences).\n",
    "- You must include at least the following tables: users and onboarding_tasks. Add supporting tables (e.g., departments, roles, task_templates, user_tasks, attachments) as needed to achieve at least third-normal-form (3NF).\n",
    "- Use appropriate SQLite types (INTEGER, TEXT, REAL). Use TEXT for ISO-8601 timestamp columns and/or TIMESTAMP where applicable.\n",
    "- For primary keys use INTEGER PRIMARY KEY or INTEGER PRIMARY KEY AUTOINCREMENT as appropriate.\n",
    "- Define FOREIGN KEYs, UNIQUE constraints, NOT NULL where appropriate, and sensible DEFAULT values.\n",
    "- Include created_at and updated_at timestamp columns with DEFAULT (CURRENT_TIMESTAMP) where appropriate.\n",
    "- Provide indexes on foreign keys and columns expected to be searched/joined (e.g., email, status, department_id).\n",
    "- Include PRAGMA foreign_keys = ON; and optionally DROP TABLE IF EXISTS statements preceding CREATE TABLE statements for idempotence.\n",
    "- Use only SQL compatible with SQLite (no vendor-specific types or ON UPDATE clauses unsupported by SQLite).\n",
    "- Do not include any narrative, comments outside SQL, or any other output. Inline SQL comments are acceptable if strictly necessary.\n",
    "- Produce only raw CREATE TABLE (and optional DROP/CREATE INDEX/PRAGMA) statements that implement the schema.\n",
    "\n",
    "Produce the final schema as raw SQLite SQL statements only.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n",
      "INSERT INTO departments (department_id, name) VALUES (1, 'Engineering'), (2, 'Human Resources'), (3, 'Sales');\n",
      "INSERT INTO roles (role_id, name, description) VALUES (1, 'Software Engineer', 'Builds and maintains software applications.'), (2, 'Engineering Team Lead', 'Manages a team of software engineers and technical projects.'), (3, 'HR Onboarding Specialist', 'Manages the new hire onboarding process and administration.');\n",
      "INSERT INTO users (user_id, full_name, email, sso_user_id, role_id, department_id, manager_id, mentor_id, hire_date) VALUES (1, 'Emily Carter', 'emily.carter@examplecorp.com', 'sso-ecarter', 2, 1, NULL, NULL, '2022-08-15'), (2, 'David Chen', 'david.chen@examplecorp.com', 'sso-dchen', 3, 2, NULL, NULL, '2021-05-20'), (3, 'Alex Johnson', 'alex.johnson@examplecorp.com', 'sso-ajohnson', 1, 1, 1, NULL, '2022-01-10'), (4, 'Sarah Lee', 'sarah.lee@examplecorp.com', 'sso-slee', 1, 1, 1, 3, '2023-10-23');\n",
      "INSERT INTO task_templates (task_template_id, title, description, task_type, estimated_duration_days) VALUES (1, 'Complete W-4 and I-9 Forms', 'Submit your tax and employment eligibility forms through the HR portal.', 'HR_FORM', 1), (2, 'Sign Employee Handbook', 'Acknowledge receipt and understanding of the company handbook.', 'HR_FORM', 1), (3, 'Company History & Values', 'Learn about our mission and the principles that guide us.', 'LEARNING_MODULE', 1), (4, 'Intro to Engineering Codebase', 'A high-level overview of our main repositories and architecture.', 'LEARNING_MODULE', 3), (5, 'Setup Local Dev Environment & Fix a Bug', 'A hands-on project to get your local environment running and make your first contribution.', 'SIMULATED_PROJECT', 5), (6, 'Schedule 1:1 with your Manager', 'Set up your first introductory meeting with your direct manager.', 'GENERAL', 1);\n",
      "INSERT INTO learning_paths (learning_path_id, name, description, role_id) VALUES (1, 'Software Engineer Onboarding Path', 'The essential learning path for all new Software Engineers.', 1);\n",
      "INSERT INTO learning_path_tasks (learning_path_task_id, learning_path_id, task_template_id, sequence_order) VALUES (1, 1, 3, 1), (2, 1, 4, 2), (3, 1, 5, 3);\n",
      "INSERT INTO onboarding_tasks (task_id, user_id, task_template_id, status, due_date, completed_at) VALUES (1, 4, 1, 'COMPLETED', '2023-10-24T23:59:59Z', '2023-10-23T14:30:00Z'), (2, 4, 2, 'COMPLETED', '2023-10-24T23:59:59Z', '2023-10-24T10:00:00Z'), (3, 4, 6, 'COMPLETED', '2023-10-25T23:59:59Z', '2023-10-23T11:00:00Z'), (4, 4, 3, 'IN_PROGRESS', '2023-10-26T23:59:59Z', NULL), (5, 4, 4, 'PENDING', '2023-10-29T23:59:59Z', NULL), (6, 4, 5, 'COMPLETED', '2023-11-03T23:59:59Z', '2023-10-27T16:00:00Z');\n",
      "INSERT INTO resources (resource_id, title, description, category, resource_type, storage_path_or_url) VALUES (1, 'Expense Reimbursement Policy', 'Official company policy on submitting expenses.', 'Policy', 'PDF', '/docs/policies/expense_policy_v2.pdf'), (2, 'Corporate Benefits Guide', 'A comprehensive guide to health, dental, and retirement benefits.', 'Benefits', 'PDF', '/docs/benefits/benefits_guide_2023.pdf'), (3, 'Engineering Team Wiki', 'Technical documentation, style guides, and best practices for the engineering team.', 'Engineering', 'URL', 'https://wiki.examplecorp.com/engineering');\n",
      "INSERT INTO task_submissions (submission_id, task_id, user_id, submission_content, storage_path) VALUES (1, 6, 4, 'Submission includes a link to the pull request and a brief summary of the fix.', 'https://git.examplecorp.com/main/pulls/1234');\n",
      "INSERT INTO submission_feedback (feedback_id, submission_id, reviewer_id, feedback_text, created_at) VALUES (1, 1, 1, 'Great work on your first PR, Sarah! The code is clean and the fix is correct. Welcome to the team!', '2023-10-28T10:00:00Z');\n"
     ]
    }
   ],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a senior Database Administrator generating realistic seed data for a newly created SQLite onboarding tool database.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "SCHEMA:\n",
    "{cleaned_schema}\n",
    "\n",
    "Task:\n",
    "Generate 5-10 total INSERT statements that populate the schema with realistic onboarding data.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output ONLY raw SQL INSERT statements (no CREATE/DROP, no comments, no explanatory text, no markdown fences).\n",
    "- Use only tables present in the schema.\n",
    "- Provide meaningful onboarding-focused data: departments, roles, users (new hire, manager, HR, IT), task templates, onboarding task instances / user task mappings, attachments (if that table exists).\n",
    "- Satisfy foreign key order: insert parent tables first (e.g., departments -> roles -> users -> task_templates -> onboarding_tasks / user_tasks -> attachments).\n",
    "- Use explicit integer primary key values starting at 1 (stable, no AUTOINCREMENT reliance in output).\n",
    "- Multi-row INSERTs encouraged to stay within the 5–10 statement limit.\n",
    "- Use realistic corporate-style emails and ISO-8601 timestamps where explicit values are needed. If a column has a DEFAULT CURRENT_TIMESTAMP you may omit it.\n",
    "- Use only the following statuses: 'pending','in_progress','completed' if a status column exists.\n",
    "- Do not exceed 10 INSERT statements total.\n",
    "- No UPDATE/DELETE statements.\n",
    "- Do not invent tables or columns not in the provided schema.\n",
    "\n",
    "Return ONLY the INSERT statements. Output must be valid SQLite SQL and adhere to the schema provided above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing database file: c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Successfully connected to database at c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Tables created successfully.\n",
      "Seed data inserted into database successfully.\n",
      "Database changes committed successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Enable foreign key constraints\n",
    "        cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if not schema_sql:\n",
    "            print(f\"Error: Could not read schema file at {schema_path}\")\n",
    "            return\n",
    "        \n",
    "        # Execute the schema SQL script.\n",
    "        # Use cursor.executescript() for multi-statement SQL strings.\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted into database successfully.\")\n",
    "            else:\n",
    "                print(f\"Warning: Could not read seed data file at {seed_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Seed data file not found at {seed_path}\")\n",
    "\n",
    "        # Commit the changes to the database.\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed successfully.\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to error.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to unexpected error.\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Remove existing database file to start fresh\n",
    "if os.path.exists(db_file):\n",
    "    os.remove(db_file)\n",
    "    print(f\"Removed existing database file: {db_file}\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
