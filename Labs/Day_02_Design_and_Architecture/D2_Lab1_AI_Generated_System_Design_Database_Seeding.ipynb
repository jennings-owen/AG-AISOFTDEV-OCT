{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:05:17,231 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd_2025-10-27_17-33-10.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n",
      "PRAGMA foreign_keys = ON;\n",
      "\n",
      "DROP TABLE IF EXISTS user_tasks;\n",
      "DROP TABLE IF EXISTS onboarding_tasks;\n",
      "DROP TABLE IF EXISTS resources;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS roles;\n",
      "DROP TABLE IF EXISTS departments;\n",
      "\n",
      "CREATE TABLE departments (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE roles (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    department_id INTEGER NOT NULL,\n",
      "    title TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (department_id) REFERENCES departments(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    full_name TEXT NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    user_type TEXT NOT NULL CHECK (user_type IN ('new_hire', 'hr_specialist', 'manager')),\n",
      "    role_id INTEGER,\n",
      "    manager_id INTEGER,\n",
      "    mentor_id INTEGER,\n",
      "    start_date TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(id),\n",
      "    FOREIGN KEY (manager_id) REFERENCES users(id),\n",
      "    FOREIGN KEY (mentor_id) REFERENCES users(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE onboarding_tasks (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    role_id INTEGER,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    task_type TEXT NOT NULL CHECK (task_type IN ('learning_module', 'hr_form', 'simulated_project')),\n",
      "    default_due_days INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE user_tasks (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    task_id INTEGER NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'in_progress', 'completed', 'overdue')),\n",
      "    due_date TEXT,\n",
      "    completed_at TEXT,\n",
      "    submission_url TEXT,\n",
      "    feedback TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    UNIQUE (user_id, task_id),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(id),\n",
      "    FOREIGN KEY (task_id) REFERENCES onboarding_tasks(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE resources (\n",
      "    id INTEGER PRIMARY KEY,\n",
      "    title TEXT NOT NULL,\n",
      "    category TEXT,\n",
      "    description TEXT,\n",
      "    resource_url TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_roles_department_id ON roles(department_id);\n",
      "CREATE INDEX idx_users_email ON users(email);\n",
      "CREATE INDEX idx_users_role_id ON users(role_id);\n",
      "CREATE INDEX idx_users_manager_id ON users(manager_id);\n",
      "CREATE INDEX idx_users_mentor_id ON users(mentor_id);\n",
      "CREATE INDEX idx_onboarding_tasks_role_id ON onboarding_tasks(role_id);\n",
      "CREATE INDEX idx_user_tasks_user_id ON user_tasks(user_id);\n",
      "CREATE INDEX idx_user_tasks_task_id ON user_tasks(task_id);\n",
      "CREATE INDEX idx_user_tasks_status ON user_tasks(status);\n",
      "CREATE INDEX idx_resources_category ON resources(category);\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a senior Database Administrator (DBA). Act only as the DBA and use the Product Requirements Document (PRD) below as the single source of truth. Do not invent features or behaviors that are not implied by the PRD.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "Task:\n",
    "Design a normalized, production-ready SQL schema for an onboarding tool based on the PRD above.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output must be SQLite-compatible SQL only.\n",
    "- Return raw SQL statements only (no explanatory text, no Markdown fences).\n",
    "- You must include at least the following tables: users and onboarding_tasks. Add supporting tables (e.g., departments, roles, task_templates, user_tasks, attachments) as needed to achieve at least third-normal-form (3NF).\n",
    "- Use appropriate SQLite types (INTEGER, TEXT, REAL). Use TEXT for ISO-8601 timestamp columns and/or TIMESTAMP where applicable.\n",
    "- For primary keys use INTEGER PRIMARY KEY or INTEGER PRIMARY KEY AUTOINCREMENT as appropriate.\n",
    "- Define FOREIGN KEYs, UNIQUE constraints, NOT NULL where appropriate, and sensible DEFAULT values.\n",
    "- Include created_at and updated_at timestamp columns with DEFAULT (CURRENT_TIMESTAMP) where appropriate.\n",
    "- Provide indexes on foreign keys and columns expected to be searched/joined (e.g., email, status, department_id).\n",
    "- Include PRAGMA foreign_keys = ON; and optionally DROP TABLE IF EXISTS statements preceding CREATE TABLE statements for idempotence.\n",
    "- Use only SQL compatible with SQLite (no vendor-specific types or ON UPDATE clauses unsupported by SQLite).\n",
    "- Do not include any narrative, comments outside SQL, or any other output. Inline SQL comments are acceptable if strictly necessary.\n",
    "- Produce only raw CREATE TABLE (and optional DROP/CREATE INDEX/PRAGMA) statements that implement the schema.\n",
    "\n",
    "Produce the final schema as raw SQLite SQL statements only.\n",
    "**Final output should be 5-7 simple tables as a starting point for development.**\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n",
      "INSERT INTO departments (id, name) VALUES (1, 'Engineering'), (2, 'Human Resources'), (3, 'Product Management');\n",
      "INSERT INTO roles (id, department_id, title) VALUES (1, 1, 'Engineering Team Lead'), (2, 1, 'Software Engineer'), (3, 2, 'HR Onboarding Specialist'), (4, 3, 'Product Manager');\n",
      "INSERT INTO users (id, full_name, email, user_type, role_id, manager_id, mentor_id, start_date) VALUES (1, 'Emily Rivera', 'emily.rivera@examplecorp.com', 'manager', 1, NULL, NULL, '2023-05-15T09:00:00Z'), (2, 'David Chen', 'david.chen@examplecorp.com', 'hr_specialist', 3, NULL, NULL, '2022-08-20T09:00:00Z'), (3, 'Michael Brown', 'michael.brown@examplecorp.com', 'manager', 2, 1, NULL, '2024-03-11T09:00:00Z'), (4, 'Sarah Jenkins', 'sarah.jenkins@examplecorp.com', 'new_hire', 2, 1, 3, '2025-10-27T09:00:00Z');\n",
      "INSERT INTO onboarding_tasks (id, role_id, title, description, task_type, default_due_days) VALUES (1, NULL, 'Complete I-9 Employment Form', 'Please complete and upload your I-9 form for employment verification.', 'hr_form', 2), (2, NULL, 'Benefits Enrollment', 'Enroll in company health, dental, and retirement plans.', 'hr_form', 5), (3, NULL, 'Company Security Policy Review', 'Read and acknowledge the company-wide security policies.', 'learning_module', 3), (4, 2, 'Engineering Codebase Introduction', 'A guided tour of our primary service repositories and coding standards.', 'learning_module', 7), (5, 2, 'Simulated Project: Build a Mini-API', 'Complete a small, self-contained project to demonstrate practical skills.', 'simulated_project', 14);\n",
      "INSERT INTO user_tasks (id, user_id, task_id, status, due_date, completed_at, submission_url, feedback) VALUES (1, 4, 1, 'completed', '2025-10-29T23:59:59Z', '2025-10-27T14:30:00Z', '/docs/completed/sarah_jenkins_i9.pdf', NULL), (2, 4, 2, 'overdue', '2025-11-01T23:59:59Z', NULL, NULL, NULL), (3, 4, 3, 'in_progress', '2025-10-30T23:59:59Z', NULL, NULL, NULL), (4, 4, 4, 'pending', '2025-11-03T23:59:59Z', NULL, NULL, NULL), (5, 4, 5, 'pending', '2025-11-10T23:59:59Z', NULL, NULL, NULL);\n",
      "INSERT INTO resources (id, title, category, description, resource_url) VALUES (1, 'Expense Reimbursement Policy', 'HR Policies', 'Official policy document for submitting and getting reimbursed for business expenses.', '/resources/expense_policy_v3.pdf'), (2, 'Company Holiday Calendar 2025', 'General Information', 'A list of all official company holidays for the upcoming year.', '/resources/holiday_calendar_2025.pdf'), (3, 'Engineering Team Style Guide', 'Engineering', 'Guidelines for code style, formatting, and best practices for the engineering team.', 'https://wiki.examplecorp.com/engineering/style-guide');\n"
     ]
    }
   ],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a senior Database Administrator generating realistic seed data for a newly created SQLite onboarding tool database.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "SCHEMA:\n",
    "{cleaned_schema}\n",
    "\n",
    "Task:\n",
    "Generate 5-10 total INSERT statements that populate the schema with realistic onboarding data.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output ONLY raw SQL INSERT statements (no CREATE/DROP, no comments, no explanatory text, no markdown fences).\n",
    "- Use only tables present in the schema.\n",
    "- Provide meaningful onboarding-focused data: departments, roles, users (new hire, manager, HR, IT), task templates, onboarding task instances / user task mappings, attachments (if that table exists).\n",
    "- Satisfy foreign key order: insert parent tables first (e.g., departments -> roles -> users -> task_templates -> onboarding_tasks / user_tasks -> attachments).\n",
    "- Use explicit integer primary key values starting at 1 (stable, no AUTOINCREMENT reliance in output).\n",
    "- Multi-row INSERTs encouraged to stay within the 5–10 statement limit.\n",
    "- Use realistic corporate-style emails and ISO-8601 timestamps where explicit values are needed. If a column has a DEFAULT CURRENT_TIMESTAMP you may omit it.\n",
    "- Use only the following statuses: 'pending','in_progress','completed' if a status column exists.\n",
    "- Do not exceed 10 INSERT statements total.\n",
    "- No UPDATE/DELETE statements.\n",
    "- Do not invent tables or columns not in the provided schema.\n",
    "\n",
    "Return ONLY the INSERT statements. Output must be valid SQLite SQL and adhere to the schema provided above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing database file: c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Successfully connected to database at c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Tables created successfully.\n",
      "Seed data inserted into database successfully.\n",
      "Database changes committed successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Enable foreign key constraints\n",
    "        cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if not schema_sql:\n",
    "            print(f\"Error: Could not read schema file at {schema_path}\")\n",
    "            return\n",
    "        \n",
    "        # Execute the schema SQL script.\n",
    "        # Use cursor.executescript() for multi-statement SQL strings.\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted into database successfully.\")\n",
    "            else:\n",
    "                print(f\"Warning: Could not read seed data file at {seed_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Seed data file not found at {seed_path}\")\n",
    "\n",
    "        # Commit the changes to the database.\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed successfully.\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to error.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to unexpected error.\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Remove existing database file to start fresh\n",
    "if os.path.exists(db_file):\n",
    "    os.remove(db_file)\n",
    "    print(f\"Removed existing database file: {db_file}\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
