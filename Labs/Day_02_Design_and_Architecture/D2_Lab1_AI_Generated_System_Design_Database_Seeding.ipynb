{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 1: AI-Generated System Design & Database Seeding\n",
    "\n",
    "**Objective:** Use the PRD artifact from Day 1 to generate a detailed SQL database schema, create realistic seed data, and then use those outputs to create and seed a live, local database file.\n",
    "\n",
    "**Estimated Time:** 150 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 2! Today, we transition from *what* we're building to *how* we'll build it. In this lab, you will act as the lead architect for the Onboarding Tool. Your task is to use the PRD to define the data structure of the application and create a tangible database artifact that will be used for the rest of the course.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the `day1_prd.md` artifact from Day 1. This document is the primary source of truth for our project and provides the necessary context for the LLM to make intelligent design suggestions.\n",
    "\n",
    "**Model Selection:**\n",
    "Feel free to experiment with different models by changing the `model_name` in `setup_llm_client()`. Models with strong reasoning capabilities, like `gpt-4o`, `o3`, or `gemini-2.5-pro`, are excellent choices for design tasks.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the PRD from the `artifacts` directory.\n",
    "- `save_artifact()`: To save the generated SQL schema and seed data.\n",
    "- `clean_llm_output()`: To remove markdown fences from the generated SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 09:51:34,655 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD from Day 1\n",
    "prd_content = load_artifact(\"artifacts/day1_prd_2025-10-27_17-33-10.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load day1_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating the SQL Schema\n",
    "\n",
    "**Task:** Use the PRD to generate a normalized SQL schema for the application.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a Database Administrator (DBA).\n",
    "2.  Provide the `prd_content` as context.\n",
    "3.  Ask the LLM to design a normalized SQL schema with at least two tables (e.g., `users` and `onboarding_tasks`).\n",
    "4.  The output should be the raw `CREATE TABLE` statements.\n",
    "5.  Save the generated SQL to `artifacts/schema.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n",
      "PRAGMA foreign_keys = ON;\n",
      "\n",
      "DROP TABLE IF EXISTS submission_feedback;\n",
      "DROP TABLE IF EXISTS project_submissions;\n",
      "DROP TABLE IF EXISTS form_submissions;\n",
      "DROP TABLE IF EXISTS user_tasks;\n",
      "DROP TABLE IF EXISTS role_task_assignments;\n",
      "DROP TABLE IF EXISTS task_templates;\n",
      "DROP TABLE IF EXISTS resources;\n",
      "DROP TABLE IF EXISTS resource_categories;\n",
      "DROP TABLE IF EXISTS users;\n",
      "DROP TABLE IF EXISTS roles;\n",
      "DROP TABLE IF EXISTS departments;\n",
      "\n",
      "CREATE TABLE departments (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE roles (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    description TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE users (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    full_name TEXT NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    sso_user_id TEXT UNIQUE,\n",
      "    user_type TEXT NOT NULL CHECK(user_type IN ('new_hire', 'manager', 'hr_specialist', 'employee')),\n",
      "    role_id INTEGER,\n",
      "    department_id INTEGER,\n",
      "    manager_id INTEGER,\n",
      "    mentor_id INTEGER,\n",
      "    start_date TEXT NOT NULL,\n",
      "    experience_level TEXT,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles (id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY (department_id) REFERENCES departments (id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY (manager_id) REFERENCES users (id) ON DELETE SET NULL,\n",
      "    FOREIGN KEY (mentor_id) REFERENCES users (id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE resource_categories (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE resources (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    content_type TEXT NOT NULL CHECK(content_type IN ('document', 'link', 'video')),\n",
      "    storage_path TEXT NOT NULL,\n",
      "    category_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (category_id) REFERENCES resource_categories (id) ON DELETE SET NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE task_templates (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    title TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    task_type TEXT NOT NULL CHECK(task_type IN ('learning_module', 'hr_form', 'simulated_project', 'checklist_item')),\n",
      "    content_url TEXT,\n",
      "    estimated_duration_minutes INTEGER,\n",
      "    is_mandatory INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now'))\n",
      ");\n",
      "\n",
      "CREATE TABLE role_task_assignments (\n",
      "    role_id INTEGER NOT NULL,\n",
      "    task_template_id INTEGER NOT NULL,\n",
      "    sequence_order INTEGER NOT NULL,\n",
      "    default_due_days INTEGER NOT NULL,\n",
      "    PRIMARY KEY (role_id, task_template_id),\n",
      "    FOREIGN KEY (role_id) REFERENCES roles (id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_template_id) REFERENCES task_templates (id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE user_tasks (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    task_template_id INTEGER NOT NULL,\n",
      "    status TEXT NOT NULL DEFAULT 'pending' CHECK(status IN ('pending', 'in_progress', 'completed', 'overdue')),\n",
      "    due_date TEXT NOT NULL,\n",
      "    completed_at TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    updated_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (task_template_id) REFERENCES task_templates (id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE form_submissions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_task_id INTEGER NOT NULL UNIQUE,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    secure_storage_path TEXT NOT NULL,\n",
      "    e_signature TEXT NOT NULL,\n",
      "    submitted_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (user_task_id) REFERENCES user_tasks (id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE project_submissions (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_task_id INTEGER NOT NULL UNIQUE,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    submission_content TEXT,\n",
      "    submission_url TEXT,\n",
      "    submitted_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (user_task_id) REFERENCES user_tasks (id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE TABLE submission_feedback (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    submission_id INTEGER NOT NULL,\n",
      "    reviewer_id INTEGER NOT NULL,\n",
      "    feedback_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (strftime('%Y-%m-%dT%H:%M:%fZ', 'now')),\n",
      "    FOREIGN KEY (submission_id) REFERENCES project_submissions (id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (reviewer_id) REFERENCES users (id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "CREATE INDEX idx_users_email ON users (email);\n",
      "CREATE INDEX idx_users_role_id ON users (role_id);\n",
      "CREATE INDEX idx_users_department_id ON users (department_id);\n",
      "CREATE INDEX idx_users_manager_id ON users (manager_id);\n",
      "CREATE INDEX idx_resources_title ON resources (title);\n",
      "CREATE INDEX idx_resources_category_id ON resources (category_id);\n",
      "CREATE INDEX idx_user_tasks_user_id ON user_tasks (user_id);\n",
      "CREATE INDEX idx_user_tasks_status ON user_tasks (status);\n",
      "CREATE INDEX idx_user_tasks_due_date ON user_tasks (due_date);\n",
      "CREATE INDEX idx_form_submissions_user_id ON form_submissions (user_id);\n",
      "CREATE INDEX idx_project_submissions_user_id ON project_submissions (user_id);\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a senior Database Administrator (DBA). Act only as the DBA and use the Product Requirements Document (PRD) below as the single source of truth. Do not invent features or behaviors that are not implied by the PRD.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "Task:\n",
    "Design a normalized, production-ready SQL schema for an onboarding tool based on the PRD above.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output must be SQLite-compatible SQL only.\n",
    "- Return raw SQL statements only (no explanatory text, no Markdown fences).\n",
    "- You must include at least the following tables: users and onboarding_tasks. Add supporting tables (e.g., departments, roles, task_templates, user_tasks, attachments) as needed to achieve at least third-normal-form (3NF).\n",
    "- Use appropriate SQLite types (INTEGER, TEXT, REAL). Use TEXT for ISO-8601 timestamp columns and/or TIMESTAMP where applicable.\n",
    "- For primary keys use INTEGER PRIMARY KEY or INTEGER PRIMARY KEY AUTOINCREMENT as appropriate.\n",
    "- Define FOREIGN KEYs, UNIQUE constraints, NOT NULL where appropriate, and sensible DEFAULT values.\n",
    "- Include created_at and updated_at timestamp columns with DEFAULT (CURRENT_TIMESTAMP) where appropriate.\n",
    "- Provide indexes on foreign keys and columns expected to be searched/joined (e.g., email, status, department_id).\n",
    "- Include PRAGMA foreign_keys = ON; and optionally DROP TABLE IF EXISTS statements preceding CREATE TABLE statements for idempotence.\n",
    "- Use only SQL compatible with SQLite (no vendor-specific types or ON UPDATE clauses unsupported by SQLite).\n",
    "- Do not include any narrative, comments outside SQL, or any other output. Inline SQL comments are acceptable if strictly necessary.\n",
    "- Produce only raw CREATE TABLE (and optional DROP/CREATE INDEX/PRAGMA) statements that implement the schema.\n",
    "\n",
    "Produce the final schema as raw SQLite SQL statements only.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Realistic Seed Data\n",
    "\n",
    "**Task:** Prompt the LLM to generate realistic seed data that conforms to the schema you just created.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide both the `prd_content` and the `cleaned_schema` as context.\n",
    "3.  Instruct the LLM to generate 5-10 realistic `INSERT` statements for your tables.\n",
    "4.  The data should be relevant to a new hire onboarding tool (e.g., sample user names and task titles like \"Complete HR Paperwork\").\n",
    "5.  Save the generated `INSERT` statements to `artifacts/seed_data.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n",
      "INSERT INTO departments (id, name) VALUES (1, 'Engineering'), (2, 'Human Resources'), (3, 'Marketing');\n",
      "INSERT INTO roles (id, name, description) VALUES (1, 'Software Engineer', 'Builds and maintains software applications.'), (2, 'Engineering Team Lead', 'Manages a team of software engineers.'), (3, 'HR Onboarding Specialist', 'Manages the new hire onboarding process.');\n",
      "INSERT INTO users (id, full_name, email, sso_user_id, user_type, role_id, department_id, manager_id, mentor_id, start_date, experience_level, is_active) VALUES (1, 'Emily Chen', 'emily.chen@corp.com', 'echen', 'manager', 2, 1, NULL, NULL, '2022-08-15', 'Senior', 1), (2, 'David Rodriguez', 'david.rodriguez@corp.com', 'drodriguez', 'hr_specialist', 3, 2, NULL, NULL, '2021-05-20', 'Mid-level', 1), (3, 'Liam Smith', 'liam.smith@corp.com', 'lsmith', 'employee', 1, 1, 1, NULL, '2023-01-10', 'Senior', 1), (4, 'Sarah Jones', 'sarah.jones@corp.com', 'sjones', 'new_hire', 1, 1, 1, 3, '2025-10-27', 'Junior', 1), (5, 'Maria Garcia', 'maria.garcia@corp.com', 'mgarcia', 'new_hire', 1, 1, 1, 3, '2025-10-01', 'Mid-level', 1);\n",
      "INSERT INTO resource_categories (id, name) VALUES (1, 'HR Policies'), (2, 'Technical Guides'), (3, 'Company Benefits');\n",
      "INSERT INTO resources (id, title, description, content_type, storage_path, category_id) VALUES (1, 'Expense Reimbursement Policy', 'How to submit expenses for reimbursement.', 'document', '/docs/expense_policy_v3.pdf', 1), (2, 'Development Environment Setup', 'A step-by-step guide to configure your local machine.', 'link', 'https://internal.wiki.corp.com/dev-setup', 2), (3, 'Health Insurance Plan Details 2025', 'Details on medical, dental, and vision plans.', 'document', '/docs/benefits_summary_2025.pdf', 3);\n",
      "INSERT INTO task_templates (id, title, description, task_type, content_url, estimated_duration_minutes, is_mandatory) VALUES (1, 'Complete W-4 and I-9 Forms', 'Submit your tax and employment eligibility forms.', 'hr_form', '/forms/w4-i9', 30, 1), (2, 'Review Employee Handbook', 'Read and acknowledge the company policies and code of conduct.', 'learning_module', '/resources/101', 60, 1), (3, 'Set Up Development Environment', 'Follow the guide to get your local development environment running.', 'checklist_item', '/resources/201', 120, 1), (4, 'Submit \"Hello World\" Microservice', 'Complete the introductory coding challenge to get familiar with our deployment pipeline.', 'simulated_project', '/projects/1', 240, 1);\n",
      "INSERT INTO role_task_assignments (role_id, task_template_id, sequence_order, default_due_days) VALUES (1, 1, 1, 1), (1, 2, 2, 3), (1, 3, 3, 2), (1, 4, 4, 7);\n",
      "INSERT INTO user_tasks (id, user_id, task_template_id, status, due_date, completed_at) VALUES (1, 4, 1, 'completed', '2025-10-28T23:59:59Z', '2025-10-27T14:05:10Z'), (2, 4, 2, 'in_progress', '2025-10-30T23:59:59Z', NULL), (3, 4, 3, 'pending', '2025-10-29T23:59:59Z', NULL), (4, 5, 1, 'completed', '2025-10-02T23:59:59Z', '2025-10-01T11:00:00Z'), (5, 5, 2, 'completed', '2025-10-04T23:59:59Z', '2025-10-02T16:30:00Z'), (6, 5, 4, 'completed', '2025-10-08T23:59:59Z', '2025-10-06T09:45:21Z');\n",
      "INSERT INTO form_submissions (id, user_task_id, user_id, secure_storage_path, e_signature, submitted_at) VALUES (1, 1, 4, '/secure/forms/sjones/w4-i9-20251027.pdf.enc', 'Sarah Jones 2025-10-27T14:05:10Z', '2025-10-27T14:05:10Z');\n",
      "INSERT INTO project_submissions (id, user_task_id, user_id, submission_url, submitted_at) VALUES (1, 6, 5, 'https://git.corp.com/mgarcia/hello-world-service/pull/1', '2025-10-06T09:45:21Z');\n"
     ]
    }
   ],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a senior Database Administrator generating realistic seed data for a newly created SQLite onboarding tool database.\n",
    "\n",
    "PRD CONTEXT:\n",
    "{prd_content}\n",
    "\n",
    "SCHEMA:\n",
    "{cleaned_schema}\n",
    "\n",
    "Task:\n",
    "Generate 5-10 total INSERT statements that populate the schema with realistic onboarding data.\n",
    "\n",
    "Requirements / Constraints:\n",
    "- Output ONLY raw SQL INSERT statements (no CREATE/DROP, no comments, no explanatory text, no markdown fences).\n",
    "- Use only tables present in the schema.\n",
    "- Provide meaningful onboarding-focused data: departments, roles, users (new hire, manager, HR, IT), task templates, onboarding task instances / user task mappings, attachments (if that table exists).\n",
    "- Satisfy foreign key order: insert parent tables first (e.g., departments -> roles -> users -> task_templates -> onboarding_tasks / user_tasks -> attachments).\n",
    "- Use explicit integer primary key values starting at 1 (stable, no AUTOINCREMENT reliance in output).\n",
    "- Multi-row INSERTs encouraged to stay within the 5â€“10 statement limit.\n",
    "- Use realistic corporate-style emails and ISO-8601 timestamps where explicit values are needed. If a column has a DEFAULT CURRENT_TIMESTAMP you may omit it.\n",
    "- Use only the following statuses: 'pending','in_progress','completed' if a status column exists.\n",
    "- Do not exceed 10 INSERT statements total.\n",
    "- No UPDATE/DELETE statements.\n",
    "- Do not invent tables or columns not in the provided schema.\n",
    "\n",
    "Return ONLY the INSERT statements. Output must be valid SQLite SQL and adhere to the schema provided above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql', overwrite=True) # rewrote on rerun\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Creating and Seeding a Live Database\n",
    "\n",
    "**Task:** This is a critical technical step. You will write a Python script to execute the generated SQL files, creating a live `onboarding.db` file that your application will use.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Complete the `create_database` function below.\n",
    "2.  The function should first connect to (and thus create) a SQLite database file named `artifacts/onboarding.db`.\n",
    "3.  It should then open and execute the `schema.sql` file to create the tables.\n",
    "4.  Finally, it should open and execute the `seed_data.sql` file to populate the tables.\n",
    "5.  Use a `try...finally` block to ensure the database connection is always closed, even if an error occurs.\n",
    "\n",
    "> **Hint:** The `try...finally` block is a crucial Python pattern. The code in the `finally` block will run whether the `try` block succeeds or fails, making it the perfect place to ensure resources like database connections are always closed.\n",
    "\n",
    "**Expected Quality:** A physical `onboarding.db` file in your `artifacts` folder. This is a tangible asset that proves your design is valid and provides a concrete foundation for backend development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing database file: c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Successfully connected to database at c:\\Users\\647020\\OneDrive - BOOZ ALLEN HAMILTON\\Desktop\\Workspace\\AG-AISOFTDEV-OCT\\artifacts\\onboarding.db\n",
      "Tables created successfully.\n",
      "Seed data inserted into database successfully.\n",
      "Database changes committed successfully.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Enable foreign key constraints\n",
    "        cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if not schema_sql:\n",
    "            print(f\"Error: Could not read schema file at {schema_path}\")\n",
    "            return\n",
    "        \n",
    "        # Execute the schema SQL script.\n",
    "        # Use cursor.executescript() for multi-statement SQL strings.\n",
    "        cursor.executescript(schema_sql)\n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted into database successfully.\")\n",
    "            else:\n",
    "                print(f\"Warning: Could not read seed data file at {seed_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Seed data file not found at {seed_path}\")\n",
    "\n",
    "        # Commit the changes to the database.\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed successfully.\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to error.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "            print(\"Database changes rolled back due to unexpected error.\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"artifacts\", \"onboarding.db\")\n",
    "schema_file = os.path.join(project_root, \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Remove existing database file to start fresh\n",
    "if os.path.exists(db_file):\n",
    "    os.remove(db_file)\n",
    "    print(f\"Removed existing database file: {db_file}\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now moved from abstract requirements to a concrete, physical database artifact. You've used an LLM to design a schema, generate realistic test data, and then used a Python script to bring that database to life. This `onboarding.db` file is the foundation upon which we will build our API in Day 3.\n",
    "\n",
    "> **Key Takeaway:** The ability to generate structured data definitions (like a SQL schema) from unstructured text (like a PRD) is a core skill in AI-assisted development. It automates a critical and often time-consuming design step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
