{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 15:52:55,150 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "# ADR-[Number]: [Brief Decision Description]\n",
      "\n",
      "**Date**: YYYY-MM-DD\n",
      "**Author(s)**: [Name/Team]\n",
      "**Stakeholders**: [List of key stakeholders, e.g., Engineering Lead, Product Manager, DevOps Team]\n",
      "\n",
      "## Status\n",
      "\n",
      "Proposed\n",
      "\n",
      "> *[Guidance: Change status to one of: `Proposed`, `Accepted`, `Rejected`, `Deprecated`, `Superseded by ADR-XXX`.]*\n",
      "\n",
      "## Context\n",
      "\n",
      "> *[Guidance: Describe the problem, the driving forces, and the constraints. This section sets the stage for the decision. What is the issue we're trying to solve? What are the business requirements, technical constraints, or user stories that influence this decision? Clearly articulate the \"why\" behind this ADR.]*\n",
      "\n",
      "**Example:**\n",
      "The user-facing application requires a persistent data store for user profiles, product information, and order history. The current system has no long-term storage, relying only on an in-memory cache, which is not suitable for production. We need a reliable, scalable, and maintainable relational database management system (RDBMS) to support transactional integrity and complex queries.\n",
      "\n",
      "**Key Requirements:**\n",
      "- ACID compliance for transactional operations.\n",
      "- Support for complex SQL queries, including joins and aggregations.\n",
      "- Good performance under a moderate-to-high concurrent load.\n",
      "- Strong community support and mature tooling.\n",
      "- Cost-effective for a startup environment.\n",
      "- Must be a managed service to reduce operational overhead.\n",
      "\n",
      "## Decision\n",
      "\n",
      "> *[Guidance: State the chosen solution clearly and concisely. Be specific about the technology, patterns, and configurations selected. This is the \"what\" of the ADR. This should be a clear and unambiguous statement of the decision.]*\n",
      "\n",
      "**Example:**\n",
      "We will use **PostgreSQL** as the primary relational database for the application.\n",
      "\n",
      "Specifically, we will use **Amazon RDS for PostgreSQL** as the managed database service.\n",
      "\n",
      "**Key Implementation Details:**\n",
      "- **Initial Instance Size**: `db.t3.medium` to balance cost and performance, with auto-scaling storage enabled.\n",
      "- **Version**: PostgreSQL 15.x or the latest stable version available on RDS at the time of implementation.\n",
      "- **Data Access Layer**: We will use a standard Object-Relational Mapping (ORM) library, such as TypeORM (for TypeScript/Node.js) or SQLAlchemy (for Python), to interact with the database.\n",
      "- **Backup Strategy**: Daily automated snapshots will be enabled via RDS, with a retention period of 14 days. Point-in-time recovery will be enabled.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "> *[Guidance: Describe the results and outcomes of making this decision. Be honest about both the positive and negative implications. This helps future readers understand the trade-offs that were made. Consider impacts on performance, security, cost, maintenance, and team skills.]*\n",
      "\n",
      "### Positive\n",
      "\n",
      "- **Maturity and Reliability**: PostgreSQL is a battle-tested, open-source RDBMS with a strong reputation for reliability, data integrity, and a rich feature set.\n",
      "- **Reduced Operational Overhead**: Using a managed service (AWS RDS) handles routine database tasks such as patching, backups, and recovery, allowing the development team to focus on application features.\n",
      "- **Strong Ecosystem**: Excellent community support, extensive documentation, and a wide range of compatible tools and libraries (ORMs, GUI clients, etc.).\n",
      "- **Scalability**: RDS provides straightforward options for vertical scaling (changing instance size) and read scalability (adding read replicas).\n",
      "\n",
      "### Negative\n",
      "\n",
      "- **Potential for Vendor Lock-in**: While PostgreSQL is open-source, using a managed service like AWS RDS introduces a dependency on a specific cloud provider. Migrating to another provider in the future would require significant effort.\n",
      "- **Less Control**: Compared to a self-hosted database, we have less control over the underlying infrastructure and specific database configurations.\n",
      "- **Relational Model Rigidity**: The schema-on-write nature of a relational database is less flexible for rapidly evolving or unstructured data compared to a NoSQL alternative. This was deemed an acceptable trade-off for the benefit of data consistency.\n",
      "\n",
      "### Considered Alternatives\n",
      "\n",
      "> *[Guidance: (Optional but recommended) Briefly mention other options that were considered and why they were not chosen. This provides valuable context for future decisions.]*\n",
      "\n",
      "- **MySQL/MariaDB**: A solid alternative, but PostgreSQL is often favored for its more advanced SQL features, data type support (e.g., JSONB), and extensibility.\n",
      "- **Self-Hosted PostgreSQL**: Rejected due to the significant operational and maintenance overhead required, which our small team cannot currently support.\n",
      "- **MongoDB (NoSQL)**: Considered for its flexibility, but rejected because our core data model is highly relational and requires strong transactional guarantees (ACID), which are native to RDBMSs like PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "adr_template_prompt = \"\"\"\n",
    "Create a comprehensive markdown template for an Architecture Decision Record (ADR) that follows industry best practices and includes the following sections:\n",
    "\n",
    "**Required Sections:**\n",
    "1. **Title** - A clear, descriptive title using the format \"ADR-[Number]: [Brief Decision Description]\"\n",
    "2. **Status** - Current state (Proposed, Accepted, Superseded, Deprecated, Rejected)\n",
    "3. **Context** - The technical and business forces, constraints, and requirements driving this decision\n",
    "4. **Decision** - The specific choice made, including key implementation details\n",
    "5. **Consequences** - Both positive and negative outcomes, trade-offs, and implications\n",
    "\n",
    "**Additional Requirements:**\n",
    "- Include metadata section with Date, Author(s), and Stakeholders\n",
    "- Provide clear placeholder text with examples for each section\n",
    "- Use proper markdown formatting with headers, lists, and emphasis\n",
    "- Include guidance comments to help users fill out each section effectively\n",
    "- Follow the standard ADR numbering convention (ADR-001, ADR-002, etc.)\n",
    "\n",
    "**Output Format:**\n",
    "- Use consistent markdown syntax with proper heading hierarchy\n",
    "- Include example content in placeholders to guide users\n",
    "- Structure the template to be both human-readable and version-control friendly\n",
    "\n",
    "The template should be professional, comprehensive, and suitable for enterprise software development teams.\n",
    "\n",
    "Return ONLY markdown. Do not include any explanations or additional text outside the markdown format. Avoid using code blocks.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)  # rewrite file on rerun of program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "Here is a research comparison of the specified database options for a new software project.\n",
      "\n",
      "### **Executive Summary: At-a-Glance Comparison**\n",
      "\n",
      "| Factor | PostgreSQL with `pgvector` | Specialized Vector Database (e.g., ChromaDB) |\n",
      "| :--- | :--- | :--- |\n",
      "| **Primary Use Case** | Applications needing vector search as a feature alongside a primary relational database. | Applications where vector search is the core, high-performance function. |\n",
      "| **Scalability** | Good for millions of vectors; scales with PostgreSQL (vertical scaling, read replicas). Horizontal scaling is complex. | Excellent; designed for billions of vectors. Natively supports sharding and horizontal scaling. |\n",
      "| **Performance** | Good to great performance. Indexing (IVFFlat, HNSW) is fast, but may lag behind dedicated solutions at extreme scale. | Best-in-class performance for vector search (ANN). Optimized indexing (HNSW) and memory management. |\n",
      "| **Ease of Use** | **High.** Leverages existing SQL knowledge. Unified system simplifies development and operations. | **Medium.** Requires learning a new API/system. Adds architectural complexity (managing two databases). |\n",
      "| **Cost** | **Low.** PostgreSQL is open-source. Cost is tied to standard compute/storage. No separate service to manage. | **Variable.** Open-source options (ChromaDB, Milvus) are self-hosted. Managed services (e.g., Pinecone) can be costly at scale. |\n",
      "| **Data Model** | **Unified.** Stores vectors, metadata, and all other relational data together. Supports ACID transactions. | **Specialized.** Stores vectors and associated metadata. Does not support complex relational queries or transactions. |\n",
      "| **Community Support** | **Massive.** Leverages the huge, mature PostgreSQL community plus a growing `pgvector` user base. | **Growing.** Strong communities around major projects, but smaller and less mature than PostgreSQL's. |\n",
      "\n",
      "---\n",
      "\n",
      "### **1. PostgreSQL with `pgvector` Extension**\n",
      "\n",
      "This option involves using the standard, battle-tested PostgreSQL relational database and enabling vector search capabilities by installing the `pgvector` open-source extension.\n",
      "\n",
      "#### **Pros**\n",
      "*   **Unified Architecture:** Store, manage, and query your vectors and your primary application data (e.g., user info, product metadata) in a single database. This drastically simplifies the tech stack, development, and operational overhead.\n",
      "*   **Transactional Integrity (ACID):** Your vector data can be part of the same transactions as your other business data, ensuring strong consistency. For example, you can guarantee that a product's embedding is created or updated in the same transaction as the product's description.\n",
      "*   **Rich Querying Capabilities:** You can combine vector similarity searches with standard SQL `WHERE` clauses, `JOIN`s, and aggregations in a single, powerful query. This is extremely effective for hybrid search (e.g., \"find similar products that are in stock and under $50\").\n",
      "*   **Mature Ecosystem:** You benefit from the entire PostgreSQL ecosystem, including robust backup/restore tools, monitoring, a vast array of client libraries, ORMs, and extensive documentation.\n",
      "*   **Lower Learning Curve:** If your team already knows SQL and PostgreSQL, adding vector search is a small incremental step rather than learning a completely new database system.\n",
      "\n",
      "#### **Cons**\n",
      "*   **Performance at Extreme Scale:** While `pgvector` is highly performant and supports modern indexes like HNSW, it may not match the raw query speed of a specialized, in-memory vector database when dealing with hundreds of millions or billions of vectors.\n",
      "*   **Scalability Limitations:** Scaling PostgreSQL for write-heavy workloads can be challenging. While it scales well for reads via replicas, true horizontal scaling for a single dataset (including vectors) is complex to implement and manage compared to natively distributed vector databases.\n",
      "*   **Generalist vs. Specialist:** PostgreSQL is a general-purpose database. Its resources (CPU, RAM, I/O) are shared between all database tasks, not just vector search. A specialized database dedicates all its resources to optimizing one task.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Specialized Vector Databases (e.g., ChromaDB, FAISS)**\n",
      "\n",
      "This option involves using a database or library designed from the ground up specifically for storing and searching high-dimensional vector embeddings.\n",
      "\n",
      "*Note: FAISS is a library from Meta AI, not a standalone database. You must build your own service layer around it. ChromaDB, Milvus, Weaviate, and Pinecone are full-fledged database systems.*\n",
      "\n",
      "#### **Pros**\n",
      "*   **Peak Performance:** These systems are built for one purpose: extremely fast and memory-efficient Approximate Nearest Neighbor (ANN) search. They use highly optimized algorithms (like HNSW) and data structures, often outperforming general-purpose solutions at large scale.\n",
      "*   **Designed for Horizontal Scalability:** Most specialized vector databases are designed to be distributed systems. They can scale out across multiple machines to handle billions of vectors and high query throughput, which is much simpler than sharding a relational database.\n",
      "*   **Developer-Friendly APIs:** The APIs are purpose-built for vector operations (`upsert`, `query`, `delete_by_id`, etc.), making the specific task of managing embeddings very straightforward.\n",
      "*   **Advanced Features:** Often include features tailored for AI applications, such as filtering queries by metadata alongside the vector search, which is a powerful and optimized combination.\n",
      "\n",
      "#### **Cons**\n",
      "*   **Increased Architectural Complexity:** This is the most significant drawback. You must maintain two separate data stores: your primary database (like PostgreSQL) for business data and the vector database for embeddings.\n",
      "*   **Data Synchronization Challenges:** You are responsible for keeping the data in your primary and vector databases in sync. If a user is deleted in your main DB, you must ensure their associated vectors are deleted from the vector DB, which can lead to consistency issues.\n",
      "*   **Lack of Transactional Guarantees:** These systems typically do not offer ACID transactions. Operations are often eventually consistent, which may not be suitable for all use cases.\n",
      "*   **Limited Querying:** You cannot perform complex relational operations like `JOIN`s. Queries are typically limited to vector similarity search combined with simple key-value metadata filtering.\n",
      "\n",
      "### **Key Decision Factors for Stakeholders**\n",
      "\n",
      "To make an informed decision, consider the following questions:\n",
      "\n",
      "1.  **Is vector search a core, mission-critical component or a supporting feature?**\n",
      "    *   **Supporting Feature:** If you're adding \"semantic search\" or \"recommendations\" to an existing application, **PostgreSQL with `pgvector`** is an excellent, low-complexity starting point.\n",
      "    *   **Core Component:** If your entire product is built around high-throughput, low-latency vector search at massive scale, a **specialized vector database** is likely the better long-term choice.\n",
      "\n",
      "2.  **What is your projected scale in the next 1-2 years?**\n",
      "    *   **Under 50 million vectors:** `pgvector` is proven to handle this scale effectively on appropriate hardware.\n",
      "    *   **Hundreds of millions to billions of vectors:** A specialized, distributed vector database is architected for this scale.\n",
      "\n",
      "3.  **What is your team's expertise?**\n",
      "    *   **Strong in SQL/PostgreSQL:** The team can be productive with `pgvector` immediately.\n",
      "    *   **Open to new technologies:** The team will need time to learn the new APIs, concepts, and operational patterns of a specialized database.\n",
      "\n",
      "4.  **How important is data consistency and unified querying?**\n",
      "    *   **Very Important:** If you need to filter vector searches based on complex, real-time business logic in your primary database, the ability to do this in a single `SQL` query with `pgvector` is a major advantage.\n",
      "    *   **Less Important:** If your vectors and metadata are relatively static and don't require complex joins with other business data, the dual-database architecture of a specialized solution is more manageable.\n"
     ]
    }
   ],
   "source": [
    "db_research_prompt = \"\"\"\n",
    "Act as an unbiased technology researcher. Research and compare the following database options for a new software project. Provide pros and cons for each option, considering factors such as scalability, performance, ease of use, cost, and community support.\n",
    "The database options to research are:\n",
    "1. PostgreSQL with the pgvector extension\n",
    "2. Using a specialized vector database like ChromaDB or FAISS\n",
    "\n",
    "Present your findings in a clear, structured format, such as a table or bullet points, to help stakeholders make an informed decision.\n",
    "Only provide results from this question. Only include well-formated markdown in your response.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Use PostgreSQL with pgvector for Vector Search Capabilities\n",
      "\n",
      "**Date**: 2023-10-27\n",
      "**Author(s)**: Core Services Team\n",
      "**Stakeholders**: Engineering Lead, Product Manager, DevOps Team, Data Science Team\n",
      "\n",
      "## Status\n",
      "\n",
      "Accepted\n",
      "\n",
      "## Context\n",
      "\n",
      "The project requires the implementation of advanced search and recommendation features, which depend on storing and querying high-dimensional vector embeddings. These features are critical for improving user engagement by providing semantic search capabilities and personalized content suggestions.\n",
      "\n",
      "Our current architecture is built on a relational data model, and we need a solution for vector search that integrates seamlessly with our existing data, such as product metadata and user profiles. The primary goal is to introduce this new capability while minimizing architectural complexity, operational overhead, and the learning curve for the development team.\n",
      "\n",
      "**Key Requirements:**\n",
      "-   Ability to store, index, and query high-dimensional vector embeddings efficiently.\n",
      "-   Support for hybrid search, allowing the combination of vector similarity search with traditional SQL filtering (e.g., `WHERE` clauses on metadata).\n",
      "-   Transactional consistency (ACID compliance) between vector data and other relational application data.\n",
      "-   A solution that avoids introducing a separate, standalone database system to manage, in order to limit operational complexity.\n",
      "-   Leverage the team's existing expertise in SQL and relational databases.\n",
      "-   Cost-effective for an initial scale of up to 50 million vectors, with a clear path for vertical scaling.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will use **PostgreSQL with the `pgvector` extension** as the unified datastore for both our primary relational data and the vector embeddings required for semantic search.\n",
      "\n",
      "We will use a managed service, such as **Amazon RDS for PostgreSQL** or an equivalent, to host our database, thereby offloading operational tasks like backups, patching, and maintenance.\n",
      "\n",
      "**Key Implementation Details:**\n",
      "-   **Extension**: The `pgvector` open-source extension will be installed and enabled on our PostgreSQL instance.\n",
      "-   **Data Model**: Vector embeddings will be stored in a `vector` type column directly within the same tables as their associated metadata (e.g., a `product_embedding` column in the `products` table).\n",
      "-   **Indexing**: To ensure high-performance queries, we will utilize an Approximate Nearest Neighbor (ANN) index. Specifically, we will use the HNSW (Hierarchical Navigable Small World) index provided by `pgvector` on all vector columns.\n",
      "-   **Querying**: The application's data access layer will be responsible for constructing hybrid SQL queries that combine vector distance operators (e.g., `<=>` for cosine distance) with standard `WHERE`, `JOIN`, and `GROUP BY` clauses.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "### Positive\n",
      "\n",
      "-   **Unified Architecture**: Storing vectors alongside our primary application data in a single database drastically simplifies the tech stack. This reduces development complexity, eliminates data synchronization issues between different systems, and lowers operational overhead.\n",
      "-   **Transactional Integrity**: By using PostgreSQL, we gain full ACID compliance for our vector data. We can guarantee that an embedding is created, updated, or deleted in the same transaction as its corresponding business data, ensuring strong data consistency.\n",
      "-   **Rich Querying Capabilities**: We can execute powerful, single-pass hybrid queries that combine vector similarity search with complex relational filters. This is a significant advantage for features like \"find similar items that are in stock and within a specific price range.\"\n",
      "-   **Mature Ecosystem and Lower Learning Curve**: The team can leverage its existing SQL and PostgreSQL knowledge, making adoption immediate. We also benefit from the entire mature PostgreSQL ecosystem of tools for monitoring, backup, and client libraries.\n",
      "-   **Cost-Effective**: We avoid the licensing, hosting, and operational costs associated with managing a second, specialized database service. The cost is consolidated into our existing PostgreSQL infrastructure.\n",
      "\n",
      "### Negative\n",
      "\n",
      "-   **Performance at Extreme Scale**: For workloads involving hundreds of millions or billions of vectors, a specialized vector database might offer lower latency. This is an acceptable trade-off, as our projected scale for the next 1-2 years (under 50 million vectors) is well within the high-performance capabilities of `pgvector` with HNSW indexing.\n",
      "-   **Scalability Limitations**: Horizontally scaling a single PostgreSQL instance for write-heavy workloads is more complex than with natively distributed vector databases. We will rely on vertical scaling and read replicas, which are sufficient for our current and projected needs.\n",
      "-   **Generalist vs. Specialist**: As a general-purpose database, PostgreSQL's resources (CPU, RAM, I/O) are shared across all operations, not dedicated solely to vector search. Performance will be managed through proper indexing and instance sizing.\n",
      "\n",
      "### Considered Alternatives\n",
      "\n",
      "-   **Specialized Vector Database (e.g., ChromaDB, Milvus, Pinecone)**: This option was seriously considered for its peak performance and native horizontal scalability. However, it was rejected due to the significant increase in architectural complexity. It would require managing and synchronizing data between two separate systems, introducing potential data consistency issues and a lack of transactional guarantees between our primary and vector data. The operational overhead and learning curve for a new database system were deemed too high for the benefits it would provide at our current scale.\n",
      "-   **Self-Hosted PostgreSQL with `pgvector`**: Rejected due to the significant operational and maintenance burden associated with managing our own database infrastructure, including backups, patching, and high availability. A managed database service is a core requirement to allow the team to focus on application development.\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "Act as a Staff Software Engineer.\n",
    "\n",
    "Using the following Architecture Decision Record (ADR) template and the database research findings, synthesize a complete ADR documenting the decision to use PostgreSQL with pgvector for the project.\n",
    "\n",
    "Based on the research findings, formally document the decision to **use PostgreSQL with pgvector** and justify this choice based on the pros and cons.\n",
    "\n",
    "## ADR Template\n",
    "{adr_template}\n",
    "\n",
    "## Database Research Findings\n",
    "{db_research_output}\n",
    "\n",
    "Please fill in all sections of the ADR, including Title, Status, Context, Decision, Consequences, and Metadata (Date, Author(s), Stakeholders). The decision should clearly state why PostgreSQL with pgvector should be chosen and provide justification based on the research findings.\n",
    "Remove any placeholder text from the ADR template and replace it with relevant content.\n",
    "Ensure the ADR is professional, clear, and suitable for enterprise software development. Only provide the markdown content of the completed ADR without any additional explanations or text.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)  # rewrite file on rerun of program.\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
