{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 09:52:58,290 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "# ADR-[Number]: [Brief Decision Description]\n",
      "\n",
      "*   **Date**: `YYYY-MM-DD`\n",
      "*   **Author(s)**: `[List of author names and/or emails]`\n",
      "*   **Stakeholders**: `[List of key stakeholders, e.g., team leads, product owners, architects]`\n",
      "\n",
      "## Status\n",
      "\n",
      "`[Proposed | Accepted | Rejected | Deprecated | Superseded by ADR-XXX]`\n",
      "\n",
      "*This section should be updated as the ADR moves through its lifecycle. See below for status definitions.*\n",
      "*   **Proposed**: This decision is under review.\n",
      "*   **Accepted**: The decision has been approved and is the current standard.\n",
      "*   **Rejected**: The decision was proposed but not approved.\n",
      "*   **Deprecated**: The decision was previously accepted but is no longer recommended. A new ADR may or may not be in place.\n",
      "*   **Superseded by ADR-XXX**: The decision has been replaced by a new decision, documented in the linked ADR.\n",
      "\n",
      "## Context\n",
      "\n",
      "*This section describes the problem, the forces at play, and the constraints that influence the decision. It should be detailed enough for a future reader to understand the \"why\" behind the decision.*\n",
      "\n",
      "**The Problem:**\n",
      "*Describe the issue, user story, or technical challenge that needs to be addressed. What is the problem we are trying to solve? Why is it important to solve it now?*\n",
      "\n",
      "**Business/Technical Drivers:**\n",
      "*List the key business requirements, technical goals, or quality attributes (e.g., performance, security, maintainability) driving this decision.*\n",
      "*   e.g., Improve system performance by 20% to meet new SLA.\n",
      "*   e.g., Reduce infrastructure costs by moving to a serverless architecture.\n",
      "*   e.g., Standardize our approach to asynchronous communication to improve developer experience.\n",
      "*   e.g., Fulfill a new compliance requirement (GDPR, etc.).\n",
      "\n",
      "**Constraints and Assumptions:**\n",
      "*List any technical, financial, or organizational constraints. Also, list any assumptions made.*\n",
      "*   e.g., Must use our existing approved cloud provider (AWS/Azure/GCP).\n",
      "*   e.g., The development team has limited experience with technology X.\n",
      "*   e.g., The solution must be implemented before the end of the current quarter.\n",
      "*   e.g., We assume the transaction volume will double in the next year.\n",
      "\n",
      "**Options Considered:**\n",
      "*Briefly list the alternative solutions that were evaluated. This demonstrates due diligence.*\n",
      "1.  **Option 1:** [Brief description of the first option].\n",
      "2.  **Option 2:** [Brief description of the second option].\n",
      "3.  **Option 3 (Do Nothing):** [Describe the implications of not making a change].\n",
      "\n",
      "*A more detailed analysis of options can be included here or linked to an external document (e.g., a Confluence page or design doc) if necessary.*\n",
      "\n",
      "## Decision\n",
      "\n",
      "*This is the core of the ADR. Clearly and concisely state the chosen solution. Be specific enough that someone can understand the decision without having to read the entire context again.*\n",
      "\n",
      "We have decided to **[state the chosen option or solution in a clear, affirmative sentence]**.\n",
      "\n",
      "**Justification:**\n",
      "*Explain why this option was chosen over the others. Connect the decision back to the context, drivers, and constraints. This is the rationale.*\n",
      "*   e.g., This option best meets the performance requirements while staying within our budget constraints.\n",
      "*   e.g., It aligns with our team's existing skillset, reducing training overhead and implementation risk.\n",
      "*   e.g., While more expensive initially, its long-term maintainability and scalability align with our strategic goals.\n",
      "\n",
      "**Implementation Details:**\n",
      "*Provide key details about how the decision will be implemented. This is not a full implementation plan, but it should cover the high-level approach and key components.*\n",
      "*   **Technology/Pattern:** [e.g., Use RabbitMQ for asynchronous messaging using the Fanout exchange pattern].\n",
      "*   **Key Responsibilities:** [e.g., The Platform team will manage the message broker infrastructure].\n",
      "*   **Phasing/Rollout Plan:** [e.g., This will be implemented first in the 'Orders' service, followed by the 'Inventory' service in Q3].\n",
      "*   **Diagrams:** [Link to or embed architecture diagrams, sequence diagrams, etc., if applicable].\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*This section is crucial for understanding the full impact of the decision. Be honest and thorough about both the positive and negative outcomes to provide a balanced view.*\n",
      "\n",
      "**Positive Consequences:**\n",
      "*List the expected benefits and positive outcomes of this decision.*\n",
      "*   e.g., Improved end-user response time for critical transactions.\n",
      "*   e.g., Decoupled services, leading to better fault tolerance and independent deployment capabilities.\n",
      "*   e.g., Standardized logging format will simplify debugging and monitoring across the platform.\n",
      "\n",
      "**Negative Consequences:**\n",
      "*List the known drawbacks, risks, and trade-offs. Every decision has trade-offs.*\n",
      "*   e.g., Increased operational complexity due to the introduction of a new component (e.g., a message broker).\n",
      "*   e.g., Requires a one-time data migration effort that will involve system downtime.\n",
      "*   e.g., Introduces a new licensing cost of $X per year.\n",
      "\n",
      "**Neutral Consequences / Implications:**\n",
      "*List any other impacts that are neither strictly positive nor negative but are important for the team to be aware of.*\n",
      "*   e.g., The development team will require training on the new technology.\n",
      "*   e.g., This decision will require updates to our CI/CD pipeline and monitoring dashboards.\n",
      "*   e.g., All future services of this type must now follow this architectural pattern.\n"
     ]
    }
   ],
   "source": [
    "adr_template_prompt = \"\"\"\n",
    "Create a comprehensive markdown template for an Architecture Decision Record (ADR) that follows industry best practices and includes the following sections:\n",
    "\n",
    "**Required Sections:**\n",
    "1. **Title** - A clear, descriptive title using the format \"ADR-[Number]: [Brief Decision Description]\"\n",
    "2. **Status** - Current state (Proposed, Accepted, Superseded, Deprecated, Rejected)\n",
    "3. **Context** - The technical and business forces, constraints, and requirements driving this decision\n",
    "4. **Decision** - The specific choice made, including key implementation details\n",
    "5. **Consequences** - Both positive and negative outcomes, trade-offs, and implications\n",
    "\n",
    "**Additional Requirements:**\n",
    "- Include metadata section with Date, Author(s), and Stakeholders\n",
    "- Provide clear placeholder text with examples for each section\n",
    "- Use proper markdown formatting with headers, lists, and emphasis\n",
    "- Include guidance comments to help users fill out each section effectively\n",
    "- Follow the standard ADR numbering convention (ADR-001, ADR-002, etc.)\n",
    "\n",
    "**Output Format:**\n",
    "- Use consistent markdown syntax with proper heading hierarchy\n",
    "- Structure the template to be both human-readable and version-control friendly\n",
    "\n",
    "The template should be professional, comprehensive, and suitable for enterprise software development teams.\n",
    "\n",
    "Return ONLY markdown. Do not include any explanations or additional text outside the markdown format. Avoid using code blocks. Do not fill in any sections or example, only provide a template with placeholders.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)  # rewrite file on rerun of program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "### **Unbiased Technology Research Report: Database Options for the Ascend Onboarding Platform**\n",
      "\n",
      "**Date:** October 26, 2023\n",
      "**Prepared By:** Unbiased Technology Researcher\n",
      "**Subject:** Comparison of PostgreSQL with `pgvector` vs. Specialized Vector Databases for the Ascend Onboarding Platform\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Executive Summary**\n",
      "\n",
      "This report analyzes two primary database approaches for the Ascend Onboarding Platform, focusing on the requirements outlined in the Product Requirements Document (PRD v1.0). The core functionality requiring vector search capabilities is the \"searchable resource library\" (Story 1.4) and future AI-powered personalization (Section 7.2).\n",
      "\n",
      "1.  **PostgreSQL with `pgvector`:** This approach integrates vector search capabilities directly into a mature, full-featured relational database. It offers significant advantages in architectural simplicity, data consistency, and reduced operational overhead, as all application data (user profiles, progress, forms, and document vectors) resides in a single system.\n",
      "2.  **Specialized Vector Database (e.g., ChromaDB):** This approach uses a purpose-built database optimized exclusively for high-speed vector similarity search. While offering potentially superior performance at a massive scale, it necessitates a more complex architecture, requiring a separate primary database (like PostgreSQL) for relational data, which introduces challenges in data synchronization, management, and cost.\n",
      "\n",
      "For the Ascend platform's current and planned scale (5,000 users/year) and its need to tightly couple relational user data with search results, **PostgreSQL with `pgvector` presents a more practical, cost-effective, and developer-friendly solution.** It simplifies the tech stack for the MVP and provides a robust foundation that can scale to meet the project's foreseeable needs.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Detailed Comparison Analysis**\n",
      "\n",
      "| Feature | PostgreSQL with `pgvector` | Specialized Vector Database (e.g., ChromaDB) |\n",
      "| :--- | :--- | :--- |\n",
      "| **Scalability** | **Pros:**<br>- Proven to scale vertically and horizontally for relational data.<br>- `pgvector` with HNSW indexing scales well into millions of vectors, which is more than sufficient for the Ascend project's document library.<br>- Can be hosted on managed services (e.g., AWS RDS, Google Cloud SQL) that handle scaling.<br><br>**Cons:**<br>- May not match the raw query-per-second (QPS) performance of a specialized database at extremely large scales (billions of vectors).<br><br>**Relevance to Ascend:**<br>The NFR of \"5,000 active new hires annually\" and a corresponding resource library is well within the comfortable scaling limits of a properly configured PostgreSQL instance with `pgvector`. | **Pros:**<br>- Architected specifically for high-throughput, low-latency vector search at massive scale.<br>- Can scale vector search capabilities independently of the primary relational database.<br><br>**Cons:**<br>- Scaling the overall system becomes more complex, as you must manage scaling for two separate database systems.<br><br>**Relevance to Ascend:**<br>The extreme scalability offered is likely overkill for the project's current scope. The added architectural complexity outweighs the benefits for the specified user load. |\n",
      "| **Performance** | **Pros:**<br>- Excellent performance for mixed workloads (transactional, relational, and vector search).<br>- With modern HNSW index support, `pgvector` provides low-latency (<100ms) approximate nearest neighbor (ANN) search, meeting the NFR of sub-3-second page loads for the resource library.<br>- A single database call can fetch and join all necessary data.<br><br>**Cons:**<br>- Vector search performance can be impacted by other heavy transactional loads on the same database instance if not properly provisioned.<br><br>**Relevance to Ascend:**<br>Performance is more than adequate for the \"searchable resource library\" (Story 1.4). The ability to perform a single query that joins vector search results with document metadata is a significant performance and simplicity win. | **Pros:**<br>- Potentially higher raw performance and lower latency for *only* the vector search component, especially when using libraries like FAISS.<br>- Isolates the performance of vector search from the primary database.<br><br>**Cons:**<br>- Overall application performance may be slower due to network latency from making multiple calls: one to the vector DB to get IDs, and a second to the primary relational DB to retrieve the actual content and metadata.<br><br>**Relevance to Ascend:**<br>The micro-optimizations in vector search speed do not justify the macro-level complexity and potential for higher overall latency from multi-database calls. |\n",
      "| **Ease of Use & Developer Experience** | **Pros:**<br>- **Single, unified system:** Drastically simplifies development, deployment, backups, and maintenance.<br>- **Familiar SQL interface:** Developers can use standard SQL to query both relational and vector data, lowering the learning curve.<br>- **Powerful queries:** Enables complex queries that combine structured filters with semantic search in one operation (e.g., \"find documents relevant to 'expense policy' that apply to the 'Software Engineer' role and were published in the last year\").<br><br>**Cons:**<br>- Requires learning the specifics of the `pgvector` extension, its data types, and indexing strategies.<br><br>**Relevance to Ascend:**<br>This is the strongest argument for `pgvector`. It directly simplifies implementing features like the personalized learning path (Story 1.1) and the resource library (Story 1.4) by allowing user data and vector content to be queried together seamlessly. | **Pros:**<br>- Often provides simple, Python-native APIs (especially ChromaDB) that are intuitive for ML engineers.<br>- Abstracts away the complexities of vector indexing.<br><br>**Cons:**<br>- **Dual database problem:** Requires managing and maintaining two separate data stores. This adds significant operational overhead.<br>- **Data synchronization:** Data must be kept consistent between the relational DB and the vector DB. If a document is deleted from the primary DB, it must also be deleted from the vector DB, adding complexity and potential for errors.<br><br>**Relevance to Ascend:**<br>The added architectural complexity creates a significant burden for the team, especially for an MVP (V1.0). It would complicate development for almost every feature, from HR forms (Story 1.5) to progress tracking (Story 1.2). |\n",
      "| **Cost** | **Pros:**<br>- **Lower Total Cost of Ownership (TCO):** Consolidating on one database system reduces hosting, maintenance, and monitoring costs.<br>- PostgreSQL and `pgvector` are both open-source and free.<br>- Costs are predictable and based on a single managed database service.<br><br>**Cons:**<br>- May require a larger, more expensive single database instance to handle the combined workload, compared to two smaller, specialized instances.<br><br>**Relevance to Ascend:**<br>A unified stack is almost always more cost-effective at the project's specified scale. It reduces both direct hosting costs and indirect operational (personnel) costs. | **Pros:**<br>- Open-source options like ChromaDB are free. You can start with a small instance dedicated to vector search.<br><br>**Cons:**<br>- **Higher TCO:** You are paying to host, manage, secure, and back up two distinct database services.<br>- Increased engineering time spent on managing the integration between the two systems translates to higher personnel costs.<br><br>**Relevance to Ascend:**<br>Running two database services will increase the monthly infrastructure bill and the engineering effort required, making it a more expensive option for achieving the project's goals. |\n",
      "| **Ecosystem & Data Integrity** | **Pros:**<br>- **ACID Compliance:** Leverages PostgreSQL's battle-tested support for transactions, ensuring strong data consistency. A single transaction can write user data and update vector embeddings atomically.<br>- **Mature Ecosystem:** Benefits from the vast ecosystem of PostgreSQL tools for backups, monitoring, replication, and security.<br>- **Data Integrity:** All data, including vectors, is backed up and restored as a single, consistent unit.<br><br>**Cons:**<br>- None of significance for this use case.<br><br>**Relevance to Ascend:**<br>The need for data integrity is critical for HR-related features like form completion (Story 1.5) and progress tracking (Story 1.2). Having vectors and application data in one transactional system is a major security and reliability advantage. | **Pros:**<br>- A growing ecosystem focused specifically on MLOps and AI applications.<br><br>**Cons:**<br>- **Lacks transactional integrity** between the two databases. It's possible for data to become out of sync (e.g., a document exists in the vector DB but has been deleted from the primary DB).<br>- The database itself is less mature than PostgreSQL, with a smaller community and fewer third-party tools for enterprise needs like advanced security auditing or disaster recovery.<br><br>**Relevance to Ascend:**<br>The risk of data inconsistency between two systems is a significant drawback for an application that manages critical employee onboarding information. |\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Final Recommendation**\n",
      "\n",
      "For the **Ascend Onboarding Platform**, the recommended approach is to use **PostgreSQL with the `pgvector` extension**.\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "1.  **Architectural Simplicity:** The project's requirements involve a tight coupling of relational data (users, roles, progress, tasks) and searchable vector data (documents, learning materials). A single database eliminates the complexity of managing and synchronizing two separate systems, which directly translates to faster development for the V1.0 MVP and lower long-term maintenance costs.\n",
      "2.  **Sufficient Performance and Scale:** The specified scale of 500 concurrent users and 5,000 annual hires is well within the capabilities of a modern PostgreSQL instance. The `pgvector` extension, with HNSW indexing, will deliver the performance needed for the resource library's semantic search feature without being overkill.\n",
      "3.  **Lower Total Cost of Ownership (TCO):** By avoiding the need for a second database service, the project will save on hosting, operational overhead, and the engineering effort required to maintain data consistency across systems.\n",
      "4.  **Data Integrity and Maturity:** Leveraging PostgreSQL's transactional guarantees and mature ecosystem ensures that this critical HR platform is built on a reliable, secure, and well-supported foundation.\n",
      "\n",
      "While a specialized vector database could be considered in the distant future if the platform scales to millions of daily active users or requires a vector-specific feature not available in `pgvector`, it is an unnecessary and counterproductive complexity for the current and foreseeable needs outlined in the PRD.\n"
     ]
    }
   ],
   "source": [
    "pdr_document = load_artifact(\"day1_prd_2025-10-28_14-03-52.md\")\n",
    "\n",
    "db_research_prompt = f\"\"\"\n",
    "Act as an unbiased technology researcher. Research and compare the following database options for a new software project. Provide pros and cons for each option, considering factors such as scalability, performance, ease of use, cost, and community support.\n",
    "The database options to research are:\n",
    "1. PostgreSQL with the pgvector extension\n",
    "2. Using a specialized vector database like ChromaDB or FAISS\n",
    "\n",
    "Compare the two options within the context of the following project requirements documentation:\n",
    "<pdr_document>\n",
    "{pdr_document}\n",
    "</pdr_document>\n",
    "\n",
    "Use web search to gather the most up-to-date information on each database option, including recent benchmarks, user reviews, and case studies.\n",
    "Present your findings in a clear, structured format, such as a table or bullet points, to help stakeholders make an informed decision.\n",
    "Only provide results from this question. Only include well-formated markdown in your response. Do not include any explanations or additional text outside the markdown format.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Choose PostgreSQL with pgvector for Primary Data and Vector Storage\n",
      "\n",
      "*   **Date**: 2023-10-30\n",
      "*   **Author(s)**: Staff Software Engineer, Ascend Platform Team\n",
      "*   **Stakeholders**: Head of Engineering, Ascend Product Owner, Lead Platform Architect\n",
      "\n",
      "## Status\n",
      "\n",
      "Accepted\n",
      "\n",
      "*This section should be updated as the ADR moves through its lifecycle. See below for status definitions.*\n",
      "*   **Proposed**: This decision is under review.\n",
      "*   **Accepted**: The decision has been approved and is the current standard.\n",
      "*   **Rejected**: The decision was proposed but not approved.\n",
      "*   **Deprecated**: The decision was previously accepted but is no longer recommended. A new ADR may or may not be in place.\n",
      "*   **Superseded by ADR-XXX**: The decision has been replaced by a new decision, documented in the linked ADR.\n",
      "\n",
      "## Context\n",
      "\n",
      "*This section describes the problem, the forces at play, and the constraints that influence the decision. It should be detailed enough for a future reader to understand the \"why\" behind the decision.*\n",
      "\n",
      "**The Problem:**\n",
      "The Ascend Onboarding Platform requires a \"searchable resource library\" (Story 1.4) that supports semantic search, allowing users to find documents based on meaning rather than just keywords. Future plans also include AI-powered personalization (Section 7.2) which relies on vector similarity search. This necessitates a database solution capable of storing and efficiently querying high-dimensional vector embeddings alongside our core relational application data (user profiles, onboarding progress, form submissions, etc.). The core technical challenge is to select a database architecture that meets these requirements without introducing undue complexity or cost for our V1.0 MVP.\n",
      "\n",
      "**Business/Technical Drivers:**\n",
      "*   **Feature Enablement:** Support the core semantic search functionality required for the resource library and future AI features.\n",
      "*   **User Experience:** Deliver fast search results, contributing to the NFR of sub-3-second page loads.\n",
      "*   **Developer Experience:** Simplify the development process by providing a clear and efficient way to query both relational and vector data.\n",
      "*   **Operational Simplicity:** Minimize the operational burden for the V1.0 MVP in terms of deployment, maintenance, backups, and monitoring.\n",
      "*   **Cost-Effectiveness:** Select a solution with a low Total Cost of Ownership (TCO) that aligns with the project's budget.\n",
      "*   **Data Integrity:** Ensure strong consistency and transactional guarantees, as the system will handle sensitive HR and employee progress data.\n",
      "\n",
      "**Constraints and Assumptions:**\n",
      "*   The platform is projected to support approximately 5,000 new hires annually.\n",
      "*   The document library is estimated to contain thousands, not billions, of documents in the foreseeable future.\n",
      "*   The development team must deliver the V1.0 MVP on an aggressive timeline, prioritizing solutions that reduce architectural complexity.\n",
      "*   We assume the team has, or can quickly acquire, proficiency in standard SQL and PostgreSQL.\n",
      "\n",
      "**Options Considered:**\n",
      "*Briefly list the alternative solutions that were evaluated. This demonstrates due diligence.*\n",
      "1.  **PostgreSQL with `pgvector`:** Use a single, mature relational database for all application data, extended with vector search capabilities via the `pgvector` extension.\n",
      "2.  **Specialized Vector Database (e.g., ChromaDB):** Implement a purpose-built vector database for similarity search, running alongside a separate primary database (e.g., PostgreSQL) for relational data.\n",
      "3.  **Do Nothing:** Forgo implementing a vector search solution. This is not a viable option as it would prevent us from building the required \"searchable resource library\" feature.\n",
      "\n",
      "## Decision\n",
      "\n",
      "*This is the core of the ADR. Clearly and concisely state the chosen solution. Be specific enough that someone can understand the decision without having to read the entire context again.*\n",
      "\n",
      "We have decided to **use PostgreSQL with the `pgvector` extension as the single, primary database for the Ascend Onboarding Platform**. This single system will be responsible for storing and serving both our core relational data and the vector embeddings required for semantic search.\n",
      "\n",
      "**Justification:**\n",
      "*Explain why this option was chosen over the others. Connect the decision back to the context, drivers, and constraints. This is the rationale.*\n",
      "This decision is based on a comprehensive analysis of our current and foreseeable needs. PostgreSQL with `pgvector` provides the optimal balance of performance, simplicity, and cost-effectiveness for the Ascend platform.\n",
      "\n",
      "*   **Architectural Simplicity:** A single, unified database drastically simplifies our architecture. It eliminates the \"dual database problem,\" removing the significant operational overhead of deploying, managing, backing up, and synchronizing two separate data stores. This directly supports our goal of a rapid MVP launch and long-term maintainability.\n",
      "*   **Superior Developer Experience:** Our team can use the familiar SQL interface to run powerful, combined queries that filter on relational data and perform semantic searches in a single operation (e.g., \"find documents relevant to 'expense policy' for the 'Software Engineer' role\"). This is significantly simpler than orchestrating calls between two different databases.\n",
      "*   **Sufficient Performance and Scale:** For our projected load of 5,000 users/year and a resource library of thousands of documents, a properly configured PostgreSQL instance with `pgvector` using HNSW indexing will provide excellent performance (<100ms for ANN search), easily meeting our NFRs. The extreme scalability of a specialized vector database is overkill for our requirements.\n",
      "*   **Lower Total Cost of Ownership (TCO):** Consolidating on a single database service reduces hosting, monitoring, and maintenance costs. It also saves significant engineering time that would otherwise be spent on managing a complex, multi-database architecture.\n",
      "*   **Data Integrity and Maturity:** We inherit the battle-tested reliability, ACID compliance, and transactional guarantees of PostgreSQL. This is critical for an HR platform, ensuring that updates to documents and their vector embeddings are atomic and consistent. We also benefit from PostgreSQL's vast and mature ecosystem of tools.\n",
      "\n",
      "**Implementation Details:**\n",
      "*Provide key details about how the decision will be implemented. This is not a full implementation plan, but it should cover the high-level approach and key components.*\n",
      "*   **Technology/Pattern:** We will use a managed PostgreSQL instance (e.g., AWS RDS, Google Cloud SQL) with the `pgvector` extension enabled.\n",
      "*   **Indexing:** Vector columns will use HNSW (Hierarchical Navigable Small World) indexes to ensure low-latency approximate nearest neighbor (ANN) search performance.\n",
      "*   **Schema:** Vector embeddings will be stored in a `vector` column directly on the same table as their corresponding document metadata (e.g., `documents` table), allowing for efficient, combined queries.\n",
      "*   **Key Responsibilities:** The Platform Backend team will be responsible for schema design, index management, and query optimization.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*This section is crucial for understanding the full impact of the decision. Be honest and thorough about both the positive and negative outcomes to provide a balanced view.*\n",
      "\n",
      "**Positive Consequences:**\n",
      "*   **Faster Development Velocity:** A simplified, single-database architecture will enable faster implementation of features for the V1.0 MVP.\n",
      "*   **Reduced Operational Complexity:** Lower overhead for deployment, backups, security, and monitoring compared to a two-database solution.\n",
      "*   **Guaranteed Data Consistency:** Using a single transactional system ensures that our relational data and vector embeddings are always in sync, eliminating a major class of potential bugs and data integrity issues.\n",
      "*   **Lower TCO:** Reduced infrastructure and engineering costs.\n",
      "*   **Powerful Querying Capabilities:** Enables developers to easily write complex queries that join structured data with semantic search results.\n",
      "\n",
      "**Negative Consequences:**\n",
      "*   **Shared Resource Contention:** Very heavy transactional workloads could potentially impact vector search performance on the same database instance if it is not provisioned with sufficient resources. This risk will be mitigated through proper instance sizing and monitoring.\n",
      "*   **Not a Hyper-Specialized Solution:** While performant, `pgvector` may not match the raw query-per-second (QPS) of a specialized vector database at extreme scales (e.g., billions of vectors). This is an acceptable trade-off as our scale is well below this threshold.\n",
      "\n",
      "**Neutral Consequences / Implications:**\n",
      "*   **Team Upskilling:** The development team will need to be trained on the specific data types, operators, and indexing strategies (HNSW) associated with the `pgvector` extension.\n",
      "*   **Monitoring Adjustments:** Our database monitoring dashboards must be configured to track the performance of both traditional and vector search queries to ensure proper resource allocation.\n",
      "*   **Architectural Standard:** This decision establishes PostgreSQL as the standard for all services within the Ascend platform that require a combination of relational and vector data storage.\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "Act as a Staff Software Engineer.\n",
    "\n",
    "Using the following Architecture Decision Record (ADR) template and the database research findings, synthesize a complete ADR documenting the decision to use PostgreSQL with pgvector for the project.\n",
    "\n",
    "Based on the research findings, formally document the decision to **use PostgreSQL with pgvector** and justify this choice based on the pros and cons.\n",
    "\n",
    "## ADR Template\n",
    "{adr_template}\n",
    "\n",
    "## Database Research Findings\n",
    "{db_research_output}\n",
    "\n",
    "Please fill in all sections of the ADR, including Title, Status, Context, Decision, Consequences, and Metadata (Date, Author(s), Stakeholders). The decision should clearly state why PostgreSQL with pgvector should be chosen and provide justification based on the research findings.\n",
    "Remove any placeholder text from the ADR template and replace it with relevant content.\n",
    "Ensure the ADR is professional, clear, and suitable for enterprise software development. Only provide the markdown content of the completed ADR without any additional explanations or text.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)  # rewrite file on rerun of program.\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
