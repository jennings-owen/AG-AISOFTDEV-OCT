{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:15:15,330 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "# ADR-[Number]: [Brief Decision Description]\n",
      "\n",
      "- **Date**: `[YYYY-MM-DD]`\n",
      "- **Author(s)**: `[List of authors, e.g., Jane Doe, John Smith]`\n",
      "- **Stakeholders**: `[List of stakeholders, e.g., Engineering Lead, Product Manager, Security Team]`\n",
      "\n",
      "## Status\n",
      "\n",
      "`[Proposed | Accepted | Rejected | Deprecated | Superseded by ADR-XXX]`\n",
      "\n",
      "*This section should be updated as the ADR moves through its lifecycle. Definitions:*\n",
      "- *`Proposed`: This decision is under review.*\n",
      "- *`Accepted`: This decision has been approved and should be followed.*\n",
      "- *`Rejected`: This decision was proposed but not approved.*\n",
      "- *`Deprecated`: This decision was once accepted but is no longer recommended.*\n",
      "- *`Superseded by ADR-XXX`: This decision has been replaced by a new one. Link to the new ADR.*\n",
      "\n",
      "## Context\n",
      "\n",
      "*This section describes the problem, technical and business forces, constraints, and requirements that led to this decision. It should set the stage and explain the \"why\" behind it.*\n",
      "\n",
      "**Problem Statement:**\n",
      "[Describe the issue that needs to be addressed or the goal to be achieved. What is the problem we are trying to solve? For example, \"Our current authentication system does not support multi-factor authentication, which is a new security requirement.\"]\n",
      "\n",
      "**Driving Forces & Constraints:**\n",
      "- **[Force/Constraint 1]:** [e.g., A business requirement for 99.9% uptime.]\n",
      "- **[Force/Constraint 2]:** [e.g., The team's existing expertise in a particular technology stack.]\n",
      "- **[Force/Constraint 3]:** [e.g., A project deadline or budget constraint.]\n",
      "- **[Force/Constraint 4]:** [e.g., A non-functional requirement like system performance or security compliance.]\n",
      "\n",
      "## Decision\n",
      "\n",
      "*This section clearly and concisely states the final decision. This is the \"what\" of the ADR.*\n",
      "\n",
      "We will adopt **[Chosen Option or Technology]** to solve the problem.\n",
      "\n",
      "**Justification:**\n",
      "[Explain why this option was chosen over others. Reference the context and constraints mentioned above. Be specific. For example, \"This option was chosen because it fully supports our security requirements, has a strong open-source community, and integrates well with our existing infrastructure, despite a slightly steeper learning curve.\"]\n",
      "\n",
      "**Implementation Details:**\n",
      "- **[Key Detail 1]:** [e.g., We will use version X.Y.Z of the library.]\n",
      "- **[Key Detail 2]:** [e.g., The service will be configured with the following specific settings.]\n",
      "- **[Key Detail 3]:** [e.g., This pattern will be applied to all new microservices handling user authentication.]\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*This section describes the resulting context after the decision is implemented. It should include both positive and negative outcomes, trade-offs, and any future implications.*\n",
      "\n",
      "**Positive Consequences:**\n",
      "- **[Benefit 1]:** [e.g., Improved system performance by an estimated 20%.]\n",
      "- **[Benefit 2]:** [e.g., Faster development cycles for new features due to a simpler API.]\n",
      "- **[Benefit 3]:** [e.g., Alignment with the company's long-term technology strategy.]\n",
      "\n",
      "**Negative Consequences & Trade-offs:**\n",
      "- **[Drawback 1]:** [e.g., Increased operational complexity and a new system to monitor.]\n",
      "- **[Drawback 2]:** [e.g., Requires a one-time training effort for the development team.]\n",
      "- **[Drawback 3]:** [e.g., Introduces a new dependency, which carries a licensing cost or a security risk.]\n",
      "\n",
      "**Future Implications:**\n",
      "- [Describe any follow-up work, potential future decisions this decision influences, or how this decision might need to be revisited. For example, \"This decision will require us to update our CI/CD pipeline and monitoring dashboards. We should plan to review the performance and cost implications in 6 months.\"]\n"
     ]
    }
   ],
   "source": [
    "adr_template_prompt = \"\"\"\n",
    "Create a comprehensive markdown template for an Architecture Decision Record (ADR) that follows industry best practices and includes the following sections:\n",
    "\n",
    "**Required Sections:**\n",
    "1. **Title** - A clear, descriptive title using the format \"ADR-[Number]: [Brief Decision Description]\"\n",
    "2. **Status** - Current state (Proposed, Accepted, Superseded, Deprecated, Rejected)\n",
    "3. **Context** - The technical and business forces, constraints, and requirements driving this decision\n",
    "4. **Decision** - The specific choice made, including key implementation details\n",
    "5. **Consequences** - Both positive and negative outcomes, trade-offs, and implications\n",
    "\n",
    "**Additional Requirements:**\n",
    "- Include metadata section with Date, Author(s), and Stakeholders\n",
    "- Provide clear placeholder text with examples for each section\n",
    "- Use proper markdown formatting with headers, lists, and emphasis\n",
    "- Include guidance comments to help users fill out each section effectively\n",
    "- Follow the standard ADR numbering convention (ADR-001, ADR-002, etc.)\n",
    "\n",
    "**Output Format:**\n",
    "- Use consistent markdown syntax with proper heading hierarchy\n",
    "- Structure the template to be both human-readable and version-control friendly\n",
    "\n",
    "The template should be professional, comprehensive, and suitable for enterprise software development teams.\n",
    "\n",
    "Return ONLY markdown. Do not include any explanations or additional text outside the markdown format. Avoid using code blocks. Do not fill in any sections or example, only provide a template with placeholders.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)  # rewrite file on rerun of program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "### **Technology Research: Database Options for the Ascend Onboarding Platform**\n",
      "\n",
      "**Prepared by:** Unbiased Technology Researcher\n",
      "**Date:** October 27, 2023\n",
      "**Subject:** Comparison of PostgreSQL with `pgvector` vs. Specialized Vector Databases for the Ascend Onboarding Platform.\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Executive Summary & Recommendation**\n",
      "\n",
      "This report analyzes two primary database architectures to support the functional and non-functional requirements of the Ascend Onboarding Platform. The core of the platform requires a robust relational database to manage users, learning paths, progress, and forms. The \"searchable resource library\" (Story 1.4) and future AI-powered features introduce a requirement for vector similarity search.\n",
      "\n",
      "| Option | Summary | Recommendation |\n",
      "| :--- | :--- | :--- |\n",
      "| **1. PostgreSQL + `pgvector`** | A unified approach where a single, mature relational database handles both structured data and vector embeddings. | **Recommended.** This option provides the best balance of performance, cost, and operational simplicity for the project's current and foreseeable needs. It avoids the complexity of managing a separate database system while delivering strong performance for the specified scale. |\n",
      "| **2. Specialized Vector DB** | A dual-database approach using a traditional RDBMS (like PostgreSQL) for core data and a dedicated vector database (like ChromaDB) for the search feature. | **Not Recommended for MVP.** While offering potentially higher performance at extreme scale, this approach introduces significant architectural and operational complexity that is unnecessary for the project's defined scope. It may be considered in the distant future if vector search loads grow exponentially. |\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Detailed Comparison Matrix**\n",
      "\n",
      "| Factor | PostgreSQL + `pgvector` | Specialized Vector Database (e.g., ChromaDB) |\n",
      "| :--- | :--- | :--- |\n",
      "| **Scalability** | **Excellent for Project Scope.** Easily handles 5,000 annual users and 500 concurrent sessions. Vertical and horizontal scaling (read replicas) are well-established. Vector index performance is strong for document collections in the thousands or low millions. | **Extremely High for Vectors.** Designed to scale to billions of vectors and handle very high query-per-second (QPS) workloads. This level of scalability is overkill for the project's stated requirements. |\n",
      "| **Performance** | **Good to Excellent.** Sub-second query times for vector searches at the required scale. Potential for resource contention between OLTP and vector search workloads on a single instance, but this is manageable with proper provisioning. | **Excellent.** Optimized for low-latency vector search. However, overall feature performance can be slower due to the need for multiple network calls (one to the vector DB, another to the primary DB to retrieve metadata). |\n",
      "| **Ease of Use & Development** | **High.** A single, familiar SQL interface for all data. Simplifies application logic, as `JOIN` operations can combine relational data (e.g., user roles) with vector search results in a single query. Reduces the learning curve for the development team. | **Moderate.** The vector DB itself may have a simple API (often Python-centric), but the overall system is more complex. Developers must manage two data sources, write data synchronization logic, and handle potential consistency issues. |\n",
      "| **Cost (Total Cost of Ownership)** | **Lower.** Consolidates infrastructure into a single managed database service (e.g., AWS RDS, Google Cloud SQL). Reduces costs for hosting, monitoring, backups, and operational overhead. | **Higher.** Requires provisioning, managing, and securing a second database service. This increases infrastructure costs and the engineering time required for maintenance and operations. |\n",
      "| **Community & Ecosystem** | **Massive.** PostgreSQL is one of the most popular and well-supported open-source databases in the world. `pgvector` is a rapidly growing and widely adopted extension with strong backing. | **Growing but Smaller.** Community is focused on the AI/ML space. Documentation and enterprise support are less mature than PostgreSQL's. Ecosystem of tools for monitoring, backup, and security is less developed. |\n",
      "| **Project Fit & Data Model** | **Very High.** Perfectly suited for the highly relational data model (users, tasks, progress). Adding `pgvector` seamlessly integrates the semantic search requirement without disrupting the core architecture. Future AI features can leverage powerful SQL `JOIN`s for personalization. | **Moderate.** A poor fit for the core relational data. Using it requires a separate primary database, creating a disjointed data architecture. It only addresses one specific feature (Story 1.4) at the cost of complicating the entire system. |\n",
      "\n",
      "---\n",
      "\n",
      "### **3. In-Depth Analysis: Pros and Cons**\n",
      "\n",
      "#### **Option 1: PostgreSQL with `pgvector` extension**\n",
      "\n",
      "This approach uses a single PostgreSQL database to store all application data. Standard relational tables will store user information, learning paths, and progress, while a table containing vector embeddings (generated from the resource library documents) will power the semantic search feature.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Unified Architecture:** A single database for all data simplifies development, deployment, and operations. No need to manage data consistency between two different systems.\n",
      "*   **Simplified Data Management:** A single source of truth for backups, security policies, and monitoring.\n",
      "*   **Powerful & Flexible Queries:** The ability to use SQL `JOIN`s to combine vector search results with structured relational data is a major advantage. For example, filtering search results based on a new hire's role or department can be done in a single, efficient query.\n",
      "*   **Mature & Reliable:** Leverages the decades of development behind PostgreSQL, including ACID compliance, transaction support, and a robust security model, which is critical for storing sensitive HR data (Story 1.5).\n",
      "*   **Cost-Effective:** Lower infrastructure and operational costs by avoiding the need for a second database service.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Potential Resource Contention:** Intensive vector search operations (especially index building) could potentially impact the performance of standard transactional queries if the database is not provisioned adequately.\n",
      "*   **Less Specialized:** May lack some of the niche, cutting-edge features or specific performance tuning knobs found in databases built exclusively for vector search. This is not a concern for the project's current scale.\n",
      "\n",
      "#### **Option 2: Using a Specialized Vector Database (e.g., ChromaDB) + a Relational DB**\n",
      "\n",
      "This approach uses two databases. A primary RDBMS (like PostgreSQL) would store the core application data, while a dedicated vector database would store embeddings of the resource library documents and handle search queries.\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "*   **Optimized Search Performance:** Can provide extremely low-latency responses for vector queries, as the entire system is optimized for this single task.\n",
      "*   **Separation of Concerns:** Isolates the resource-intensive search workload from the primary transactional database, guaranteeing that search spikes won't impact core application performance.\n",
      "*   **AI-Centric Developer Experience:** Often feature APIs and SDKs (e.g., Python) that are very intuitive for developers working on the AI/ML part of the stack.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "*   **Increased Architectural Complexity:** The team must deploy, manage, monitor, and secure two separate database systems. This significantly increases operational overhead.\n",
      "*   **Data Synchronization Challenges:** Requires building and maintaining a process to keep the data in both databases consistent. For example, when a policy document is updated or deleted in the primary DB, the corresponding vector embedding must be updated or deleted in the vector DB. This is a common source of bugs and data drift.\n",
      "*   **Inefficient Data Retrieval:** To display search results with relevant metadata (like document title, author, or access permissions), the application must perform a two-step query: first, query the vector DB to get a list of document IDs, and second, use those IDs to query the primary relational DB. This adds complexity and network latency.\n",
      "*   **Limited Query Capabilities:** Vector databases do not support transactions or complex relational queries. Filtering search results based on user permissions stored in the primary database is complex and inefficient.\n",
      "*   **Higher Total Cost of Ownership (TCO):** Costs are higher due to running a second database service and the additional engineering effort required to manage the dual-system architecture.\n"
     ]
    }
   ],
   "source": [
    "pdr_document = load_artifact(\"day1_prd_2025-10-28_14-03-52.md\")\n",
    "\n",
    "db_research_prompt = f\"\"\"\n",
    "Act as an unbiased technology researcher. Research and compare the following database options for a new software project. Provide pros and cons for each option, considering factors such as scalability, performance, ease of use, cost, and community support.\n",
    "The database options to research are:\n",
    "1. PostgreSQL with the pgvector extension\n",
    "2. Using a specialized vector database like ChromaDB or FAISS\n",
    "\n",
    "Compare the two options within the context of the following project requirements documentation:\n",
    "<pdr_document>\n",
    "{pdr_document}\n",
    "</pdr_document>\n",
    "\n",
    "Use web search to gather the most up-to-date information on each database option, including recent benchmarks, user reviews, and case studies.\n",
    "Present your findings in a clear, structured format, such as a table or bullet points, to help stakeholders make an informed decision.\n",
    "Only provide results from this question. Only include well-formated markdown in your response. Do not include any explanations or additional text outside the markdown format.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Database Selection for Vector Search and Relational Data\n",
      "\n",
      "- **Date**: `2023-10-30`\n",
      "- **Author(s)**: `Staff Software Engineer`\n",
      "- **Stakeholders**: `Engineering Lead, Product Manager, DevOps Team, Security Team`\n",
      "\n",
      "## Status\n",
      "\n",
      "`Accepted`\n",
      "\n",
      "*This decision has been approved and should be followed.*\n",
      "\n",
      "## Context\n",
      "\n",
      "**Problem Statement:**\n",
      "The Ascend Onboarding Platform requires a database solution that can manage both highly structured, relational data (users, learning paths, progress) and support vector similarity search. This dual requirement is driven by the need for a robust transactional backend and new AI-powered features, starting with a \"searchable resource library\" (Story 1.4), which relies on semantic search over document embeddings. The challenge is to select an architecture that fulfills both needs without introducing unnecessary complexity or cost.\n",
      "\n",
      "**Driving Forces & Constraints:**\n",
      "- **Dual Data Model Requirement:** The system must efficiently store and query both traditional relational data and high-dimensional vector embeddings.\n",
      "- **Data Integrity and Security:** As the system will handle sensitive employee and HR data (Story 1.5), ACID compliance, transactional integrity, and a mature security model are non-negotiable requirements.\n",
      "- **Performance at Scale:** The solution must provide sub-second query latency for both relational lookups and vector searches for a projected scale of 5,000 annual users and 500 concurrent sessions.\n",
      "- **Operational Simplicity:** To maintain development velocity and control costs, the chosen architecture should minimize operational overhead related to deployment, monitoring, backups, and maintenance.\n",
      "- **Developer Experience:** The solution should be easy for the development team to adopt and use, ideally leveraging existing skills (like SQL) and simplifying application logic.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will adopt **PostgreSQL with the `pgvector` extension** as the single, primary database for the Ascend Onboarding Platform.\n",
      "\n",
      "**Justification:**\n",
      "This decision was made after a detailed comparison with a dual-database approach (a relational database plus a specialized vector database). PostgreSQL with `pgvector` is the superior choice for our current and foreseeable needs for the following reasons:\n",
      "\n",
      "1.  **Unified Architecture:** It eliminates the significant architectural and operational complexity of managing two separate database systems. This simplifies development, deployment, monitoring, backups, and security, directly addressing our constraint for operational simplicity.\n",
      "2.  **Simplified & Powerful Queries:** It allows us to combine relational filters and vector similarity searches within a single, atomic SQL query. For example, we can filter search results based on a user's role or department (stored in a relational table) in one efficient operation. This avoids the latency and complexity of a two-step query process required by a dual-database setup.\n",
      "3.  **Cost-Effectiveness:** Consolidating into a single managed PostgreSQL instance results in a significantly lower Total Cost of Ownership (TCO) by reducing infrastructure hosting costs and the engineering hours required for maintenance.\n",
      "4.  **Maturity and Reliability:** We gain the full benefits of PostgreSQL's decades of development, including robust ACID compliance, transactional integrity, and a world-class security model. This is critical for the core functionality of the platform and for handling sensitive HR data.\n",
      "5.  **Sufficient Performance and Scalability:** The research findings confirm that `pgvector` provides excellent performance for our projected scale (thousands to low millions of vectors), meeting our sub-second query requirements. PostgreSQL's well-established scaling patterns (vertical scaling, read replicas) provide a clear path for future growth.\n",
      "\n",
      "**Implementation Details:**\n",
      "- **Hosting:** We will use a managed PostgreSQL service (e.g., AWS RDS, Google Cloud SQL) to offload administrative overhead.\n",
      "- **Extension:** The `pgvector` extension will be enabled on the database instance.\n",
      "- **Schema:** Vector data will be stored in a `vector(n)` column, where `n` is the dimensionality of the model's embeddings.\n",
      "- **Indexing:** We will use an HNSW (Hierarchical Navigable Small World) index on vector columns to ensure fast and efficient approximate nearest neighbor (ANN) searches.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "**Positive Consequences:**\n",
      "- **Reduced Complexity:** A single data store simplifies the application's data access layer and reduces the cognitive load on developers.\n",
      "- **Faster Development:** Teams can move faster as they do not need to build or maintain data synchronization logic between two different databases.\n",
      "- **Lower TCO:** Infrastructure and operational costs will be significantly lower compared to running and managing two database systems.\n",
      "- **Enhanced Data Integrity:** Keeping all related data in a single transactional system eliminates the risk of data drift or inconsistency between a relational and vector database.\n",
      "\n",
      "**Negative Consequences & Trade-offs:**\n",
      "- **Potential Resource Contention:** Intensive vector operations (like index building) could potentially impact the performance of standard transactional queries. This risk will be mitigated through proper instance sizing, resource monitoring, and scheduling intensive operations during off-peak hours.\n",
      "- **Team Upskilling:** The development team will require training on the specific features of `pgvector` and best practices for vector indexing and querying.\n",
      "- **Not Hyper-Specialized:** While performant, `pgvector` may not match the raw query-per-second (QPS) of a specialized vector database at extreme scales (billions of vectors). This is an acceptable trade-off, as our current and projected scale is well within `pgvector`'s capabilities.\n",
      "\n",
      "**Future Implications:**\n",
      "- Our database monitoring strategy must be enhanced to include metrics specific to vector index health and search query performance.\n",
      "- This decision establishes PostgreSQL as the central data platform. Future features requiring new data types will be evaluated for their compatibility with the PostgreSQL ecosystem first.\n",
      "- We should plan to review this decision if the vector data grows exponentially beyond millions of records or if vector search performance becomes a system-wide bottleneck, at which point a hybrid or specialized solution could be reconsidered.\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "Act as a Staff Software Engineer.\n",
    "\n",
    "Using the following Architecture Decision Record (ADR) template and the database research findings, synthesize a complete ADR documenting the decision to use PostgreSQL with pgvector for the project.\n",
    "\n",
    "Based on the research findings, formally document the decision to **use PostgreSQL with pgvector** and justify this choice based on the pros and cons.\n",
    "\n",
    "## ADR Template\n",
    "{adr_template}\n",
    "\n",
    "## Database Research Findings\n",
    "{db_research_output}\n",
    "\n",
    "Please fill in all sections of the ADR, including Title, Status, Context, Decision, Consequences, and Metadata (Date, Author(s), Stakeholders). The decision should clearly state why PostgreSQL with pgvector should be chosen and provide justification based on the research findings.\n",
    "Remove any placeholder text from the ADR template and replace it with relevant content.\n",
    "Ensure the ADR is professional, clear, and suitable for enterprise software development. Only provide the markdown content of the completed ADR without any additional explanations or text.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)  # rewrite file on rerun of program.\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
