{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 16:23:55,507 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "# ADR-[Number]: [Brief Decision Description]\n",
      "\n",
      "*   **Date**: `[YYYY-MM-DD]`\n",
      "*   **Author(s)**: `[List of author names]`\n",
      "*   **Stakeholders**: `[List of key stakeholders, e.g., Product Owner, Lead Engineer, Architect]`\n",
      "\n",
      "## Status\n",
      "\n",
      "`[Proposed | Accepted | Rejected | Deprecated | Superseded by ADR-XXX]`\n",
      "\n",
      "<!-- Keep this status line clear and simple. Update it as the ADR moves through its lifecycle. -->\n",
      "\n",
      "## Context\n",
      "\n",
      "<!--\n",
      "This section describes the \"why\". What is the problem, issue, or force that triggered this decision?\n",
      "- What is the business or technical problem we are trying to solve?\n",
      "- What are the constraints (e.g., technology, skills, cost, time)?\n",
      "- What are the requirements or user stories that this decision addresses?\n",
      "- What alternative options were considered? (Briefly mention them here; a more detailed comparison can be in a separate section if needed, but often it's sufficient to frame the context).\n",
      "-->\n",
      "\n",
      "[Describe the business and technical context for the decision. This should include the problem statement, relevant constraints, and the driving forces behind making a choice. Be clear and concise.]\n",
      "\n",
      "## Decision\n",
      "\n",
      "<!--\n",
      "This section describes the \"what\". Be specific and clear about the choice that was made.\n",
      "- State the chosen option clearly.\n",
      "- Explain the key technical details of the decision.\n",
      "- Provide a rationale for why this option was chosen over others.\n",
      "- Include diagrams, code snippets, or links to other documents if they help clarify the decision.\n",
      "-->\n",
      "\n",
      "We will [describe the chosen solution in a clear and concise statement].\n",
      "\n",
      "For example: We will adopt **[Technology/Pattern X]** to solve **[Problem Y]**.\n",
      "\n",
      "### Implementation Details\n",
      "\n",
      "- **[Detail 1]**: [e.g., Key library or framework to be used and its version.]\n",
      "- **[Detail 2]**: [e.g., High-level integration plan or changes to existing components.]\n",
      "- **[Detail 3]**: [e.g., New patterns or conventions the team must follow.]\n",
      "\n",
      "### Rationale\n",
      "\n",
      "[Explain *why* this decision was made. This could include how it aligns with our architectural principles, its advantages over alternatives, or how it directly addresses the requirements and constraints outlined in the Context section.]\n",
      "\n",
      "## Consequences\n",
      "\n",
      "<!--\n",
      "This section describes the \"so what\". Every decision has trade-offs. Be honest and thorough about the implications.\n",
      "This helps future readers understand the full picture and prevents re-litigation of the decision.\n",
      "-->\n",
      "\n",
      "### Positive Consequences\n",
      "\n",
      "- [List the positive outcomes, benefits, and improvements. e.g., \"Improved performance by X%\", \"Reduced development time for new features\", \"Better alignment with the team's existing skill set.\"]\n",
      "- [Another positive consequence.]\n",
      "\n",
      "### Negative Consequences\n",
      "\n",
      "- [List the negative outcomes, risks, and trade-offs. e.g., \"Introduces a new technology that requires training\", \"Increases operational complexity\", \"Locks us into a specific vendor.\"]\n",
      "- [Another negative consequence.]\n",
      "\n",
      "### Neutral Consequences / Risks to Mitigate\n",
      "\n",
      "- [List any neutral implications or risks that need to be managed. e.g., \"The team will need to undergo training on the new framework\", \"This will require a refactor of the existing [Component Z]\", \"We need to monitor [Metric A] to ensure performance does not degrade.\"]\n",
      "- [Another neutral consequence or risk.]\n"
     ]
    }
   ],
   "source": [
    "adr_template_prompt = \"\"\"\n",
    "Create a comprehensive markdown template for an Architecture Decision Record (ADR) that follows industry best practices and includes the following sections:\n",
    "\n",
    "**Required Sections:**\n",
    "1. **Title** - A clear, descriptive title using the format \"ADR-[Number]: [Brief Decision Description]\"\n",
    "2. **Status** - Current state (Proposed, Accepted, Superseded, Deprecated, Rejected)\n",
    "3. **Context** - The technical and business forces, constraints, and requirements driving this decision\n",
    "4. **Decision** - The specific choice made, including key implementation details\n",
    "5. **Consequences** - Both positive and negative outcomes, trade-offs, and implications\n",
    "\n",
    "**Additional Requirements:**\n",
    "- Include metadata section with Date, Author(s), and Stakeholders\n",
    "- Provide clear placeholder text with examples for each section\n",
    "- Use proper markdown formatting with headers, lists, and emphasis\n",
    "- Include guidance comments to help users fill out each section effectively\n",
    "- Follow the standard ADR numbering convention (ADR-001, ADR-002, etc.)\n",
    "\n",
    "**Output Format:**\n",
    "- Use consistent markdown syntax with proper heading hierarchy\n",
    "- Structure the template to be both human-readable and version-control friendly\n",
    "\n",
    "The template should be professional, comprehensive, and suitable for enterprise software development teams.\n",
    "\n",
    "Return ONLY markdown. Do not include any explanations or additional text outside the markdown format. Avoid using code blocks. Do not fill in any sections or example, only provide a template with placeholders.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)  # rewrite file on rerun of program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "### **Database Technology Research & Comparison for the Ascend Onboarding Platform**\n",
      "\n",
      "**Date:** October 26, 2023\n",
      "**Prepared by:** Unbiased Technology Researcher\n",
      "**Subject:** Comparison of PostgreSQL with pgvector vs. Specialized Vector Databases for the Ascend Onboarding Platform, based on the Product Requirements Document (PRD) v1.0.\n",
      "\n",
      "---\n",
      "\n",
      "### **Executive Summary**\n",
      "\n",
      "This report analyzes two primary database architectures to support the Ascend Onboarding Platform. The platform's requirements indicate a strong need for storing and managing structured, relational data (user profiles, progress tracking, form data) and a specific, growing need for semantic search capabilities (searchable resource library, future AI features).\n",
      "\n",
      "1.  **PostgreSQL with pgvector:** A unified approach using a single, robust relational database that is extended to handle vector data for semantic search.\n",
      "2.  **Specialized Vector Database (e.g., ChromaDB, Milvus):** A dual-database approach, using a traditional relational database for structured data and a purpose-built vector database for search and AI features. *(Note: FAISS is a library for similarity search, not a standalone database. It requires significant engineering effort to build a production service around it. This analysis will focus on full-featured vector databases like ChromaDB as the comparative option.)*\n",
      "\n",
      "The analysis concludes that for the scale and requirements outlined in the PRD, **PostgreSQL with the pgvector extension is the more suitable choice.** It offers a significantly simpler architecture, lower operational overhead, and sufficient performance for the platform's V1.0 and near-future needs, without the added complexity and cost of managing a second database system.\n",
      "\n",
      "---\n",
      "\n",
      "### **Detailed Comparison Matrix**\n",
      "\n",
      "| Factor | PostgreSQL with pgvector Extension | Specialized Vector Database (e.g., ChromaDB) | Analysis in the Context of the Ascend PRD |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| **Data Model & Use Case Fit** | **Excellent Fit.** The vast majority of the platform's data is relational (users, roles, tasks, progress, forms, mentor assignments). `pgvector` adds the necessary vector search capability for Story 1.4 (Resource Library) directly within the same system. | **Partial Fit.** Excellent for Story 1.4 and future AI features. However, it cannot handle the core relational data, necessitating a second database (like PostgreSQL) anyway. This creates a more complex, hybrid architecture. | The project is predominantly relational. A unified database that can handle both data types simplifies development, data integrity, and operations. A dual-database system introduces complexity for a single feature in V1.0. |\n",
      "| **Performance** | **Sufficient for Project Scale.** `pgvector`'s HNSW index provides low-latency (<100ms) ANN search, which is more than adequate for the \"searchable resource library\" and will easily meet the <3 second page load NFR. Joins with relational data (e.g., filtering search by user role) are highly efficient. | **Potentially Higher for Vector Search.** At massive scale (billions of vectors), a specialized DB may offer lower latency for pure vector search. However, this performance advantage is likely negligible for the projected scale of the Ascend resource library. It also introduces network latency for queries between the two databases. | The number of documents in the resource library will likely be in the thousands, not millions. At this scale, the performance difference for vector search is not a compelling reason to adopt a more complex architecture. The ability to perform fast, combined SQL and vector queries in one system is a major performance benefit for `pgvector`. |\n",
      "| **Scalability** | **Sufficient for Project Scale.** PostgreSQL is known for its robust scalability. The system is required to support 5,000 active new hires annually, a scale well within PostgreSQL's capabilities. Vector indexes can be scaled along with the main database instance. | **Excellent for Vector Data.** Designed to scale to billions of vectors and high-throughput vector operations. This is likely overkill for the project's current scope but provides a clear path for massive AI-centric growth. | The specified scale of 500 concurrent users and 5,000 annual hires does not justify the scalability benefits of a dedicated vector database. PostgreSQL can comfortably handle this load for both its relational and vector components. |\n",
      "| **Ease of Use & Development** | **High.** Developers can use a single language (SQL) and a single connection for all data operations. This simplifies the tech stack, reduces cognitive load, and leverages existing team skills. Combining vector search with relational filters is a single, straightforward query. | **Moderate to Low.** Requires managing two separate systems, two different APIs/query languages, and two different data models. Ensuring data consistency and synchronization between the relational and vector databases (e.g., document metadata, user permissions) adds significant development and operational complexity. | The unified approach of `pgvector` dramatically simplifies development for features like the resource library. A developer can write one query to find relevant documents and check if the current user has permission to view them. In a dual-db setup, this would require at least two separate API calls and application-level logic to join the results. |\n",
      "| **Cost** | **Lower.** Cost is contained to a single managed database instance (e.g., on AWS RDS, Google Cloud SQL). This simplifies billing and reduces infrastructure overhead. Open-source nature means no licensing fees. | **Higher.** Costs are incurred for two separate managed database services. Even if using open-source versions, the operational cost of deploying, managing, monitoring, and backing up two distinct systems is significantly higher. | For a new project, minimizing operational complexity and infrastructure cost is critical. The single-database architecture is more cost-effective in both direct service fees and indirect engineering time. |\n",
      "| **Community & Ecosystem** | **Vast and Mature.** PostgreSQL has one of the largest, most active, and well-supported open-source communities. `pgvector` is a widely adopted and actively maintained extension with excellent documentation and community support. | **Growing but Newer.** The vector database space is rapidly evolving, with several competing projects. Communities are smaller and more fragmented than PostgreSQL's. Long-term support and stability can be less certain compared to a decades-old project like PostgreSQL. | Relying on the mature PostgreSQL ecosystem provides a stable and reliable foundation for the Ascend platform, reducing project risk. |\n",
      "\n",
      "---\n",
      "\n",
      "### **Pros and Cons Summary**\n",
      "\n",
      "#### **1. PostgreSQL with pgvector**\n",
      "\n",
      "**Pros:**\n",
      "*   **Unified Architecture:** Manages relational and vector data in one system, drastically simplifying development, operations, and maintenance.\n",
      "*   **Operational Simplicity:** Single point for backups, security, monitoring, and scaling.\n",
      "*   **Powerful Queries:** Allows for combined queries that filter relational data (e.g., user roles, content tags) and perform vector similarity search in a single, atomic operation.\n",
      "*   **Cost-Effective:** Lower infrastructure and operational costs compared to managing two separate database systems.\n",
      "*   **Mature Ecosystem:** Leverages the immense stability, security, and community support of PostgreSQL.\n",
      "*   **Transactional Integrity:** ACID compliance for all data, including vector metadata, ensures data consistency.\n",
      "\n",
      "**Cons:**\n",
      "*   **Not a Specialized Tool:** May not match the raw vector search performance of specialized databases at extremely large scales (billions of vectors), which is out of scope for this project.\n",
      "*   **Extension Management:** Requires managing a database extension, though this is a standard and well-supported process in modern PostgreSQL.\n",
      "\n",
      "#### **2. Specialized Vector Database (e.g., ChromaDB)**\n",
      "\n",
      "**Pros:**\n",
      "*   **Optimized for Vector Search:** Purpose-built for high-throughput, low-latency Approximate Nearest Neighbor (ANN) search.\n",
      "*   **ML-Centric Features:** Often includes APIs and features specifically designed for machine learning and AI workflows.\n",
      "*   **Scales to Billions of Vectors:** Designed for massive-scale AI applications.\n",
      "\n",
      "**Cons:**\n",
      "*   **Increased Architectural Complexity:** Requires a dual-database system, adding significant overhead for data synchronization, consistency, and operations.\n",
      "*   **Higher Total Cost of Ownership (TCO):** Increased costs from running a second database service and the additional engineering time required to manage the integration.\n",
      "*   **Data Siloing:** Separates vector data from its relational metadata, making combined queries complex and requiring application-level joins.\n",
      "*   **Immature Ecosystem:** The technology is newer, with a smaller community and potentially less long-term stability compared to PostgreSQL.\n",
      "*   **Overkill for Project Scope:** The capabilities are far beyond the stated requirements of the Ascend platform's V1.0 and near-future roadmap.\n"
     ]
    }
   ],
   "source": [
    "pdr_document = load_artifact(\"day1_prd_2025-10-28_14-03-52.md\")\n",
    "\n",
    "db_research_prompt = f\"\"\"\n",
    "Act as an unbiased technology researcher. Research and compare the following database options for a new software project. Provide pros and cons for each option, considering factors such as scalability, performance, ease of use, cost, and community support.\n",
    "The database options to research are:\n",
    "1. PostgreSQL with the pgvector extension\n",
    "2. Using a specialized vector database like ChromaDB or FAISS\n",
    "\n",
    "Compare the two options within the context of the following project requirements documentation:\n",
    "<pdr_document>\n",
    "{pdr_document}\n",
    "</pdr_document>\n",
    "\n",
    "Use web search to gather the most up-to-date information on each database option, including recent benchmarks, user reviews, and case studies.\n",
    "Present your findings in a clear, structured format, such as a table or bullet points, to help stakeholders make an informed decision.\n",
    "Only provide results from this question. Only include well-formated markdown in your response. Do not include any explanations or additional text outside the markdown format.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Use PostgreSQL with pgvector for Primary Data and Vector Storage\n",
      "\n",
      "*   **Date**: `2023-10-27`\n",
      "*   **Author(s)**: `Staff Software Engineer`\n",
      "*   **Stakeholders**: `Product Owner, Lead Engineer, Architect`\n",
      "\n",
      "## Status\n",
      "\n",
      "`Accepted`\n",
      "\n",
      "<!-- Keep this status line clear and simple. Update it as the ADR moves through its lifecycle. -->\n",
      "\n",
      "## Context\n",
      "\n",
      "The Ascend Onboarding Platform requires a robust database solution to manage its core data. The platform's data model is primarily relational, including user profiles, progress tracking, roles, and form data. Additionally, a key feature (Story 1.4) requires a searchable resource library with semantic search capabilities, which necessitates the storage and efficient querying of vector embeddings.\n",
      "\n",
      "The core technical challenge is to select a database architecture that effectively handles both structured relational data and unstructured vector data without introducing unnecessary complexity or cost. The platform is projected to support 5,000 new hires annually with up to 500 concurrent users, a scale that requires a reliable and performant solution.\n",
      "\n",
      "The two primary architectural options considered were:\n",
      "1.  A unified approach using a single relational database extended with vector capabilities (e.g., PostgreSQL with pgvector).\n",
      "2.  A dual-database approach, using a traditional relational database for structured data and a separate, specialized vector database (e.g., ChromaDB, Milvus) for search features.\n",
      "\n",
      "This decision record evaluates these options to determine the most suitable path forward for the platform's initial version and near-future growth.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will adopt **PostgreSQL with the pgvector extension** as the unified database for the Ascend Onboarding Platform. This single system will be responsible for storing and managing all primary relational data as well as the vector embeddings required for semantic search features.\n",
      "\n",
      "### Implementation Details\n",
      "\n",
      "- **Database Service**: We will use a managed PostgreSQL instance (e.g., AWS RDS, Google Cloud SQL) that supports the `pgvector` extension.\n",
      "- **Schema**: Tables requiring search capabilities (e.g., the `resources` table) will include a column of type `vector` to store embeddings.\n",
      "- **Indexing**: To ensure low-latency queries, we will create HNSW (Hierarchical Navigable Small World) indexes on all `vector` columns.\n",
      "- **Application Logic**: The application will interact with a single database connection for all data operations, including combined queries that filter on relational attributes (e.g., user role) and perform similarity searches on vectors.\n",
      "\n",
      "### Rationale\n",
      "\n",
      "This decision is based on the principle of choosing the simplest architecture that meets our requirements. The research findings clearly indicate that PostgreSQL with pgvector is an excellent fit for the project's current and foreseeable needs.\n",
      "\n",
      "-   **Architectural Simplicity**: A unified database eliminates the significant operational and development complexity of managing a dual-database system. Issues like data synchronization, consistency, and separate monitoring/backup procedures are avoided.\n",
      "-   **Cost-Effectiveness**: Using a single managed database service results in a lower Total Cost of Ownership (TCO) compared to running and maintaining two distinct systems.\n",
      "-   **Sufficient Performance and Scale**: For the project's specified scale (thousands of documents, not millions or billions), `pgvector`'s HNSW index provides low-latency (<100ms) vector search, which is more than adequate to meet our non-functional requirements. PostgreSQL itself is well-proven to handle the required user load.\n",
      "-   **Powerful, Atomic Queries**: The ability to combine relational filters and vector similarity search in a single, atomic SQL query is a major advantage. This simplifies application logic for features like filtering search results by user role or content tags, and it is highly performant.\n",
      "-   **Mature and Stable Ecosystem**: We are building on PostgreSQL, a technology with decades of production use, a vast community, and robust tooling. This reduces project risk compared to adopting a newer, less mature vector database technology.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "### Positive Consequences\n",
      "\n",
      "-   **Reduced Operational Overhead**: A single system for backups, security, monitoring, and scaling simplifies infrastructure management.\n",
      "-   **Faster Development Velocity**: Developers can leverage existing SQL skills and work with a single, consistent data access layer, reducing cognitive load and accelerating feature development.\n",
      "-   **Data Integrity**: All data, including vector metadata, benefits from PostgreSQL's ACID compliance, ensuring strong transactional consistency.\n",
      "-   **Lower Infrastructure Costs**: Costs are contained to a single database service, avoiding the expense of a second managed database.\n",
      "\n",
      "### Negative Consequences\n",
      "\n",
      "-   **Not a Hyper-Specialized Tool**: At a massive scale (billions of vectors), a dedicated vector database might offer superior raw search performance. However, this scale is far beyond the project's current scope and roadmap.\n",
      "-   **Extension Management**: The architecture depends on a database extension. While `pgvector` is well-supported, this adds a dependency that must be managed during database upgrades and maintenance.\n",
      "\n",
      "### Neutral Consequences / Risks to Mitigate\n",
      "\n",
      "-   **Team Upskilling**: The development team will need to be trained on the specific syntax and best practices for querying vector data and managing indexes within `pgvector`.\n",
      "-   **Performance Monitoring**: We must establish monitoring for combined relational and vector queries to ensure performance remains acceptable as data volume and query complexity grow.\n",
      "-   **Embedding Pipeline**: This decision necessitates the creation of a separate process for generating and updating the vector embeddings for our resource library content. This is a required component for any semantic search solution and is not unique to this choice.\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "Act as a Staff Software Engineer.\n",
    "\n",
    "Using the following Architecture Decision Record (ADR) template and the database research findings, synthesize a complete ADR documenting the decision to use PostgreSQL with pgvector for the project.\n",
    "\n",
    "Based on the research findings, formally document the decision to **use PostgreSQL with pgvector** and justify this choice based on the pros and cons.\n",
    "\n",
    "## ADR Template\n",
    "{adr_template}\n",
    "\n",
    "## Database Research Findings\n",
    "{db_research_output}\n",
    "\n",
    "Please fill in all sections of the ADR, including Title, Status, Context, Decision, Consequences, and Metadata (Date, Author(s), Stakeholders). The decision should clearly state why PostgreSQL with pgvector should be chosen and provide justification based on the research findings.\n",
    "Remove any placeholder text from the ADR template and replace it with relevant content.\n",
    "Ensure the ADR is professional, clear, and suitable for enterprise software development. Only provide the markdown content of the completed ADR without any additional explanations or text.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)  # rewrite file on rerun of program.\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
